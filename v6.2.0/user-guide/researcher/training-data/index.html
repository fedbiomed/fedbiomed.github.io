<!DOCTYPE html><html> <head><meta charset=UTF-8><meta name=viewport content="width=device-width, initial-scale=1"><meta name=robots context="index, archive"><!--  --><script>
      const versions_json = "../../../../versions.json";
      const search_worker_js = "../../../assets/javascript/search-worker.js";
      const search_index_json = "../../../search/search_index.json";
      const base_url = '../../..';
    </script><!-- Site title --><title>The Method `training_data` in Training Plan - Fed-BioMed</title><link rel=icon type=image/x-icon href=../../../favicon.ico><!-- Page description --><meta name=description content="The method `training_data` of the training plan is needed to load and process the dataset deployed on the nodes. It is a method that has to be defined in every training plan class."><!-- Page keywords --><meta name=keywords content="training data,training plan,fedbiomed, loading dataset in FL"><!-- Page author --><!-- Latest compiled and minified CSS --><link rel=stylesheet href=https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css integrity=sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu crossorigin=anonymous><!-- Bootstrap Icons --><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css><link href=../../../assets/_mkdocstrings.css rel=stylesheet><link href=../../../assets/css/style.css rel=stylesheet></head> <body> <header> <div class="container-fluid top-bar"> <div class=brand> <a href=/ > <img src=../../../assets/img/fedbiomed-logo-small.png> </a> </div> <nav class=top> <ul> <li class> <a href=../../..>Home</a> </li> <li class> <a href=../../../getting-started/what-is-fedbiomed/ >User Documentation</a> </li> <li class> <a href=../../../pages/about-us/ >About</a> </li> <li id=clicker class=has-sub> More <i class="bi bi-chevron-down"></i> <ul class=sub-nav-menu> <li class> <a href=../../../#funding>Funding</a> </li> <li class> <a href=../../../news/ >News</a> </li> <li class> <a href=../../../#contributors>Contributors</a> </li> <li class> <a href=../../../#users>Users</a> </li> <li class> <a href=../../../pages/roadmap/ >Roadmap</a> </li> <li class> <a href=../../../#citation>How to Cite Us</a> </li> <li class> <a href=../../../#contact-us>Contact Us</a> </li> </ul> </li> </ul> </nav> </div> <div class="container-fluid top-bar-mobile"> <div class=mobile-bar> <div class=brand> <a href=../../../ > <img src=../../../assets/img/fedbiomed-logo-small.png> </a> </div> <div class=hum-menu> <img class=open src=../../../assets/img/menu.svg> <img class=close style=display:none src=../../../assets/img/cancel.svg> </div> </div> <nav class=top-mobile> <ul> <li class> <a href=../../..>Home</a> </li> <li class> <a href=../../../getting-started/what-is-fedbiomed/ >User Documentation</a> </li> <li class> <a href=../../../pages/about-us/ >About</a> </li> <li id=clicker class=has-sub> More <i class="bi bi-chevron-down"></i> <ul class=sub-nav-menu> <li class> <a href=../../../#funding>Funding</a> </li> <li class> <a href=../../../news/ >News</a> </li> <li class> <a href=../../../#contributors>Contributors</a> </li> <li class> <a href=../../../#users>Users</a> </li> <li class> <a href=../../../pages/roadmap/ >Roadmap</a> </li> <li class> <a href=../../../#citation>How to Cite Us</a> </li> <li class> <a href=../../../#contact-us>Contact Us</a> </li> </ul> </li> </ul> </nav> </div> </header> <div class=main> <!-- Home page --> <div class=container-fluid> <div class=doc-row> <div class=left-col> <div class=sidebar-doc> <nav class=sidebar-inner> <ul class="sidebar-menu-left sub"> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Getting Started <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../getting-started/what-is-fedbiomed/ class>What's Fed-BioMed</a> </li> <li class> <a href=../../../getting-started/fedbiomed-architecture/ class>Fedbiomed Architecture</a> </li> <li class> <a href=../../../getting-started/fedbiomed-workflow/ class>Fedbiomed Workflow</a> </li> <li class> <a href=../../../getting-started/installation/ class>Installation</a> </li> <li class> <a href=../../../getting-started/basic-example/ class>Basic Example</a> </li> <li class> <a href=../../../getting-started/configuration/ class>Configuration</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Tutorials <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> PyTorch <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/pytorch/01_PyTorch_MNIST_Single_Node_Tutorial/ class>PyTorch MNIST Basic Example</a> </li> <li class> <a href=../../../tutorials/pytorch/02_Create_Your_Custom_Training_Plan/ class>How to Create Your Custom PyTorch Training Plan</a> </li> <li class> <a href=../../../tutorials/pytorch/03_PyTorch_Used_Cars_Dataset_Example/ class>PyTorch Used Cars Dataset Example</a> </li> <li class> <a href=../../../tutorials/pytorch/05_Transfer-learning_tutorial_usingDenseNet-121/ class>Transfer-learning in Fed-BioMed tutorial</a> </li> <li class> <a href=../../../tutorials/pytorch/04-Aggregation_in_Fed-BioMed/ class>PyTorch aggregation methods in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> MONAI <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/monai/01_monai-2d-image-classification/ class>Federated 2d image classification with MONAI</a> </li> <li class> <a href=../../../tutorials/monai/02_monai-2d-image-registration/ class>Federated 2d XRay registration with MONAI</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Scikit-Learn <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/scikit-learn/01_sklearn_MNIST_classification_tutorial/ class>MNIST classification with Scikit-Learn Classifier (Perceptron)</a> </li> <li class> <a href=../../../tutorials/scikit-learn/02_sklearn_sgd_regressor_tutorial/ class>Fed-BioMed to train a federated SGD regressor model</a> </li> <li class> <a href=../../../tutorials/scikit-learn/03-other-scikit-learn-models/ class>Implementing other Scikit Learn models for Federated Learning</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Optimizers <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/optimizers/01-fedopt-and-scaffold/ class>Advanced optimizers in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> FLamby <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/flamby/ class>Introduction</a> </li> <li class> <a href=../../../tutorials/flamby/flamby-integration-into-fedbiomed/ class>FLamby in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Advanced <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/advanced/in-depth-experiment-configuration/ class>In Depth Experiment Configuration</a> </li> <li class> <a href=../../../tutorials/advanced/training-with-gpu/ class>PyTorch model training using a GPU</a> </li> <li class> <a href=../../../tutorials/advanced/breakpoints/ class>Breakpoints</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Security <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/security/differential-privacy-with-opacus-on-fedbiomed/ class>Using Differential Privacy with OPACUS on Fed-BioMed</a> </li> <li class> <a href=../../../tutorials/security/non-private-local-central-dp-monai-2d-image-registration/ class>Local and Central DP with Fed-BioMed: MONAI 2d image registration</a> </li> <li class> <a href=../../../tutorials/security/training-with-approved-training-plans/ class>Training Process with Training Plan Management</a> </li> <li class> <a href=../../../tutorials/security/secure-aggregation/ class>Training with Secure Aggregation</a> </li> <li class> <a href=../../../tutorials/concrete-ml/concrete-ml/ class>End-to-end Privacy Preserving Training and Inference on Medical Data</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Biomedical data <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/medical/medical-image-segmentation-unet-library/ class>Brain Segmentation</a> </li> </ul> </li> </ul> </li> <li data-adress=sub-1 class="current has-sub-side"> <div href class="parent-list current "> User Guide <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub active "> <li class> <a href=../../glossary/ class>Glossary</a> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Datasets <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../datasets/ class>Introduction</a> </li> <li class> <a href=../../datasets/default-datasets/ class>Default Datasets</a> </li> <li class> <a href=../../datasets/image-dataset/ class>Image Datasets</a> </li> <li class> <a href=../../datasets/tabular-dataset/ class>Tabular Datasets</a> </li> <li class> <a href=../../datasets/medical-folder-dataset/ class>Medical Datasets</a> </li> <li class> <a href=../../datasets/custom-dataset/ class>Adding your Custom Dataset</a> </li> <li class> <a href=../../datasets/native-dataset/ class>Adding a Native Dataset</a> </li> <li class> <a href=../../datasets/applying-transformations/ class>Applying Transformations</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Deployment <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../deployment/deployment/ class>Introduction</a> </li> <li class> <a href=../../deployment/deployment-vpn/ class>VPN Deployment</a> </li> <li class> <a href=../../deployment/matrix/ class>Network matrix</a> </li> <li class> <a href=../../deployment/security-model/ class>Security model</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Node <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../nodes/configuring-nodes/ class>Configuring Nodes</a> </li> <li class> <a href=../../nodes/deploying-datasets/ class>Deploying Datasets</a> </li> <li class> <a href=../../nodes/training-plan-security-manager/ class>Training Plan Management</a> </li> <li class> <a href=../../nodes/using-gpu/ class>Using GPU</a> </li> <li class> <a href=../../nodes/node-gui/ class>Node GUI</a> </li> </ul> </li> <li data-adress=sub-1 class="current has-sub-side"> <div href class="parent-list current "> Researcher <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub active "> <li class> <a href=../training-plan/ class>Training Plan</a> </li> <li class=current> <a href=./ class="link current">Training Data</a> </li> <li class> <a href=../experiment/ class>Experiment</a> </li> <li class> <a href=../aggregation/ class>Aggregation</a> </li> <li class> <a href=../listing-datasets-and-selecting-nodes/ class>Listing Datasets and Selecting Nodes</a> </li> <li class> <a href=../model-testing-during-federated-training/ class>Model Validation on the Node Side</a> </li> <li class> <a href=../tensorboard/ class>Tensorboard</a> </li> </ul> </li> <li class> <a href=../../advanced-optimization/ class>Optimization</a> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Secure Aggregation <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../secagg/introduction/ class>Introduction</a> </li> <li class> <a href=../../secagg/configuration/ class>Configuration</a> </li> <li class> <a href=../../secagg/researcher-interface/ class>Managing Secure Aggregation in Researcher</a> </li> </ul> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Developer <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> API Reference <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Common <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../developer/api/common/certificate_manager/ class>Certificate Manager</a> </li> <li class> <a href=../../../developer/api/common/cli/ class>CLI</a> </li> <li class> <a href=../../../developer/api/common/config/ class>Config</a> </li> <li class> <a href=../../../developer/api/common/constants/ class>Constants</a> </li> <li class> <a class href=../../../developer/api/common/data.md>Data</a> </li> <li class> <a href=../../../developer/api/common/db/ class>DB</a> </li> <li class> <a href=../../../developer/api/common/exceptions/ class>Exceptions</a> </li> <li class> <a href=../../../developer/api/common/ipython/ class>IPython</a> </li> <li class> <a href=../../../developer/api/common/json/ class>Json</a> </li> <li class> <a href=../../../developer/api/common/logger/ class>Logger</a> </li> <li class> <a href=../../../developer/api/common/message/ class>Message</a> </li> <li class> <a href=../../../developer/api/common/metrics/ class>Metrics</a> </li> <li class> <a href=../../../developer/api/common/models/ class>Model</a> </li> <li class> <a class href=../../../developer/api/common/mpc_controller.md>MPC controller</a> </li> <li class> <a href=../../../developer/api/common/optimizers/ class>Optimizers</a> </li> <li class> <a href=../../../developer/api/common/privacy/ class>Privacy</a> </li> <li class> <a href=../../../developer/api/common/secagg/ class>Secagg</a> </li> <li class> <a href=../../../developer/api/common/secagg_manager/ class>Secagg Manager</a> </li> <li class> <a href=../../../developer/api/common/serializer/ class>Serializer</a> </li> <li class> <a href=../../../developer/api/common/singleton/ class>Singleton</a> </li> <li class> <a href=../../../developer/api/common/synchro/ class>Synchro</a> </li> <li class> <a href=../../../developer/api/common/tasks_queue/ class>TasksQueue</a> </li> <li class> <a href=../../../developer/api/common/training_plans/ class>TrainingPlans</a> </li> <li class> <a href=../../../developer/api/common/training_args/ class>TrainingArgs</a> </li> <li class> <a href=../../../developer/api/common/utils/ class>Utils</a> </li> <li class> <a href=../../../developer/api/common/validator/ class>Validator</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Node <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../developer/api/node/cli/ class>CLI</a> </li> <li class> <a href=../../../developer/api/node/cli_utils/ class>CLI Utils</a> </li> <li class> <a href=../../../developer/api/node/config/ class>Config</a> </li> <li class> <a href=../../../developer/api/node/dataset_manager/ class>DatasetManager</a> </li> <li class> <a href=../../../developer/api/node/history_monitor/ class>HistoryMonitor</a> </li> <li class> <a href=../../../developer/api/node/node/ class>Node</a> </li> <li class> <a href=../../../developer/api/node/node_state_manager/ class>NodeStateManager</a> </li> <li class> <a href=../../../developer/api/node/requests/ class>Requests</a> </li> <li class> <a href=../../../developer/api/node/round/ class>Round</a> </li> <li class> <a href=../../../developer/api/node/secagg/ class>Secagg</a> </li> <li class> <a href=../../../developer/api/node/secagg_manager/ class>Secagg Manager</a> </li> <li class> <a href=../../../developer/api/node/training_plan_security_manager/ class>TrainingPlanSecurityManager</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Researcher <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../developer/api/researcher/aggregators/ class>Aggregators</a> </li> <li class> <a href=../../../developer/api/researcher/cli/ class>CLI</a> </li> <li class> <a href=../../../developer/api/researcher/config/ class>Config</a> </li> <li class> <a href=../../../developer/api/researcher/datasets/ class>Datasets</a> </li> <li class> <a href=../../../developer/api/researcher/federated_workflows/ class>Federated Workflows</a> </li> <li class> <a href=../../../developer/api/researcher/filetools/ class>Filetools</a> </li> <li class> <a href=../../../developer/api/researcher/jobs/ class>Jobs</a> </li> <li class> <a href=../../../developer/api/researcher/monitor/ class>Monitor</a> </li> <li class> <a href=../../../developer/api/researcher/node_state_agent/ class>NodeStateAgent</a> </li> <li class> <a href=../../../developer/api/researcher/requests/ class>Requests</a> </li> <li class> <a href=../../../developer/api/researcher/secagg/ class>Secagg</a> </li> <li class> <a href=../../../developer/api/researcher/strategies/ class>Strategies</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Transport <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../developer/api/transport/client/ class>Client</a> </li> <li class> <a href=../../../developer/api/transport/controller/ class>Controller</a> </li> <li class> <a href=../../../developer/api/transport/node_agent/ class>NodeAgent</a> </li> <li class> <a href=../../../developer/api/transport/server/ class>Server</a> </li> </ul> </li> </ul> </li> <li class> <a href=../../../developer/usage_and_tools/ class>Usage and Tools</a> </li> <li class> <a href=../../../developer/ci/ class>Continuous Integration</a> </li> <li class> <a href=../../../developer/definition-of-done/ class>Definition of Done</a> </li> <li class> <a href=../../../developer/development-environment/ class>Development Environment</a> </li> <li class> <a href=../../../developer/testing-in-fedbiomed/ class>Testing in Fed-BioMed</a> </li> <li class> <a href=../../../developer/messaging/ class>RPC Protocol and Messages</a> </li> </ul> </li> <li class> <a href=../../../support/troubleshooting/ class>FAQ & Troubleshooting</a> </li> </ul> </nav> </div> </div> <div class=main-col> <main class=main-docs> <article> <h1 id=loading-dataset-for-training>Loading Dataset for Training</h1> <p>Datasets in the nodes are saved on the disk. Therefore, before the training, each node should load these datasets from the file system. Since the type of datasets (image, tabular, etc.) and the way of loading might vary from one to another, the user (researcher) should define a method called <code>training_data</code>. The method <code>training_data</code> is mandatory for each training plan (<code>TorchTrainingPlan</code> and <code>SKLearnTrainingPlan</code>). If it is not defined nodes will return an error at the very beginning of the first round.</p> <h2 id=defining-the-method-training-data>Defining The Method Training Data</h2> <p>The method <code>training_data</code> defines the logic related to loading data on the node. In particular, it defines:</p> <ul> <li>the type of data and the <code>Dataset</code> class</li> <li>any preprocessing (either data transforms, imputation, or augmentation)</li> <li>also implicitly defines the <code>DataLoader</code> for iterating over the data</li> </ul> <p>This method takes no inputs and returns a <a href=./#the-datamanager-return-type><code>DataManager</code></a>, therefore its signature is:</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>fedbiomed</span><span class=o>.</span><span class=n>common</span><span class=o>.</span><span class=n>datamanager</span><span class=o>.</span><span class=n>DataManager</span>
</code></pre></div> <p>The <code>training_data</code> method is always part of the training plan, as follows:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>TorchTrainingPlan</span>

<span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>TorchTrainingPlan</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>pass</span>
        <span class=c1># ....</span>
    <span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>pass</span>
</code></pre></div> <p>For details on how arguments are passed to the data loader, please refer to the section below <a href=./#passing-arguments-to-data-loaders>Passing arguments to data loaders</a>.</p> <h3 id=the-datamanager-return-type>The <code>DataManager</code> return type</h3> <p>The method <code>training_data</code> should always return <code>DataManager</code> of Fed-BioMed defined in the module <code>fedbiomed.common.datamanager.DataManager</code>. <code>DataManager</code> has been designed for managing different types of data objects for different types of training plans. It is also responsible for splitting a given dataset into training and validation subsets if model validation is activated in the experiment.</p> <div class="admonition info"> <p class=admonition-title>What is a <code>DataManager</code>?</p> <p>A <code>DataManager</code> is a Fed-BioMed concept that makes the link between a <code>Dataset</code> and the corresponding <code>DataLoader</code>. It has a generic interface that is framework-agnostic (Pytorch, sklearn, etc...)</p> </div> <p><code>DataManager</code> takes two main input arguments as <code>dataset</code> and <code>target</code>. In most cases, <code>dataset</code> should be an instance of one of PyTorch <code>Dataset</code>, and <code>target</code> should be <code>None</code>.</p> <p>For handling backwards compatibility and some simple cases, a user does not have to instantiate a <code>Dataset</code> object. User can pass the argument <code>dataset</code> as Numpy <code>ndarray</code>, <code>pd.DataFrame</code> or <code>pd.Series</code>. The argument <code>target</code> should then be an instance of one of Numpy <code>ndarray</code>, <code>pd.DataFrame</code> or <code>pd.Series</code>. By default, the argument <code>target</code> is <code>None</code>. If <code>target</code> is <code>None</code> the data manager considers that the <code>dataset</code> is an object that includes both input and target variables. This is the case where the dataset is an instance of the PyTorch dataset. <strong>If <code>dataset</code> is an instance of Numpy <code>Array</code> or Pandas <code>DataFrame</code>, it is mandatory to provide the <code>target</code> variable.</strong></p> <p>For handling any arbitrary type of data, a user is also allowed to define a <a href=../../datasets/custom-dataset/ ><code>CustomDataset</code></a>, where the user directly writes how to <code>read</code> and <code>get_item</code> from the dataset. In this case, it is upto the user to whether to pass the targets through the <code>dataset</code> object, <code>target</code> variable or to not give targets (unsupervised) at all.</p> <p>As it is mentioned, <code>DataManager</code> is capable of managing/configuring datasets/data-loaders based on the training plans that are going to be used for training. This configuration is necessary since each training plan requires different types of data loader/batch iterator, but it is handled by the framework and requires no user action.</p> <h2 id=defining-training-data-in-different-training-plans>Defining Training Data in Different Training Plans</h2> <h3 id=defining-training-data-for-pytorch-based-training-plans>Defining Training Data for PyTorch Based Training Plans</h3> <p>In the following code snippet using the classical syntax, a PyTorch-based training plan returns a <code>DataManager</code> object instantiated with a <code>Dataset</code>, and <code>target</code> is unused (<code>None</code>)</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>TorchTrainingPlan</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.datamanager</span> <span class=kn>import</span> <span class=n>DataManager</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.dataset</span> <span class=kn>import</span> <span class=n>MnistDataset</span>

<span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>TorchTrainingPlan</span><span class=p>):</span>
    <span class=k>def</span> <span class=nf>init_model</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># ....</span>
    <span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># ....</span>
    <span class=k>def</span> <span class=nf>init_optimizer</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># ....</span>

    <span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>dataset</span> <span class=o>=</span> <span class=n>MnistDataset</span><span class=p>()</span>
        <span class=n>loader_arguments</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;shuffle&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}</span>
        <span class=k>return</span> <span class=n>DataManager</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=o>**</span><span class=n>loader_arguments</span><span class=p>)</span>
</code></pre></div> <p>In the following code snippet using backwards compatible syntax, <code>training_data</code> of PyTorch-based training plan returns a <code>DataManager</code> object instantiated with <code>dataset</code> and <code>target</code> as <code>pd.Series</code>. Since PyTorch-based training requires a PyTorch <code>DataLoader</code>, <code>DataManager</code> converts <code>pd.Series</code> to a proper <code>torch.utils.data.Dataset</code> object and create a PyTorch <code>DataLoader</code> to pass it to the training loop on the node side.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>TorchTrainingPlan</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.datamanager</span> <span class=kn>import</span> <span class=n>DataManager</span>

<span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>TorchTrainingPlan</span><span class=p>):</span>
    <span class=k>def</span> <span class=nf>init_model</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># ....</span>
    <span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># ....</span>
    <span class=k>def</span> <span class=nf>init_optimizer</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># ....</span>

    <span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>feature_cols</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model_args</span><span class=p>()[</span><span class=s2>&quot;feature_cols&quot;</span><span class=p>]</span>
        <span class=n>dataset</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset_path</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>delimiter</span><span class=o>=</span><span class=s1>&#39;,&#39;</span><span class=p>)</span>
        <span class=n>X</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span><span class=mi>0</span><span class=p>:</span><span class=n>feature_cols</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>
        <span class=n>y</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span><span class=n>feature_cols</span><span class=p>]</span>
        <span class=k>return</span> <span class=n>DataManager</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>target</span><span class=o>=</span><span class=n>y</span><span class=o>.</span><span class=n>values</span><span class=p>,</span> <span class=p>)</span>
</code></pre></div> <p>It is also possible to define a custom PyTorch <code>Dataset</code> and use it in the <code>DataManager</code> without declaring the argument <code>target</code>.</p> <p><div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
<span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>Dataset</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>TorchTrainingPlan</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.datamanager</span> <span class=kn>import</span> <span class=n>DataManager</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.dataset</span> <span class=kn>import</span> <span class=n>CustomDataset</span>

<span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>TorchTrainingPlan</span><span class=p>):</span>

    <span class=k>class</span> <span class=nc>CelebaDataset</span><span class=p>(</span><span class=n>CustomDataset</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Any custom dataset should inherit from the CustomDataset class&quot;&quot;&quot;</span>

        <span class=c1># we dont load the full data of the images, we retrieve the image with the get item.</span>
        <span class=c1># in our case, each image is 218*178 * 3colors. there is 67533 images. this take at least 7G of ram</span>
        <span class=c1># loading images when needed takes more time during training but it won&#39;t impact the ram usage as much as loading everything</span>

        <span class=k>def</span> <span class=nf>read</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>input_file</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>dataset_path</span><span class=p>,</span><span class=n>sep</span><span class=o>=</span><span class=s1>&#39;,&#39;</span><span class=p>,</span><span class=n>index_col</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
            <span class=n>x_train</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>input_file</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span><span class=mi>0</span><span class=p>:</span><span class=n>features</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>
            <span class=n>y_train</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>input_file</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span><span class=n>features</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>X_train</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>x_train</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>()</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>Y_train</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>y_train</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>()</span>

        <span class=k>def</span> <span class=nf>get_item</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>index</span><span class=p>):</span>
            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>X_train</span><span class=p>[</span><span class=n>idx</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>Y_train</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>

        <span class=k>def</span> <span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
            <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>Y_train</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Custom dataset and other dependencies&quot;&quot;&quot;</span>
        <span class=n>deps</span> <span class=o>=</span> <span class=p>[</span>
            <span class=s2>&quot;from fedbiomed.common.dataset import CustomDataset&quot;</span>
        <span class=p>]</span>
        <span class=k>return</span> <span class=n>deps</span>

    <span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>feature_cols</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model_args</span><span class=p>()[</span><span class=s2>&quot;feature_cols&quot;</span><span class=p>]</span>
        <span class=n>dataset</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>CSVDataset</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset_path</span><span class=p>,</span> <span class=n>feature_cols</span><span class=p>)</span>
        <span class=n>loader_kwargs</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;batch_size&#39;</span><span class=p>:</span> <span class=n>batch_size</span><span class=p>,</span> <span class=s1>&#39;shuffle&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}</span>
        <span class=k>return</span> <span class=n>DataManager</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>dataset</span><span class=p>,</span> <span class=o>**</span><span class=n>loader_kwargs</span><span class=p>)</span>
</code></pre></div> In the code snippet above, <code>loader_kwargs</code> contains the arguments that are going to be used while creating a PyTorch <code>DataLoader</code>.</p> <h3 id=defining-training-data-for-sklearn-based-training-plans>Defining Training Data for SkLearn Based Training Plans</h3> <p>The operations in the <code>training_data</code> for SkLearn based training plans are not much different than<code>TorchTrainingPlan</code>.</p> <p>In the following code snippet using the classical syntax, a SkLearn-based training plan returns a <code>DataManager</code> object instantiated with a <code>Dataset</code>, and <code>target</code> is unused (<code>None</code>)</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>FedPerceptron</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.datamanager</span> <span class=kn>import</span> <span class=n>DataManager</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.dataset</span> <span class=kn>import</span> <span class=n>MnistDataset</span>

<span class=k>class</span> <span class=nc>SkLearnClassifierTrainingPlan</span><span class=p>(</span><span class=n>FedPerceptron</span><span class=p>):</span>
    <span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># ....</span>

    <span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=o>...</span>

        <span class=n>dataset</span> <span class=o>=</span> <span class=n>MnistDataset</span><span class=p>(</span><span class=n>transform</span><span class=o>=...</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>DataManager</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>dataset</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</code></pre></div> <p>In the following code snippet using backwards compatible syntax, <code>training_data</code> of SkLearn training plan returns a <code>DataManager</code> object instantiated with <code>dataset</code> and <code>target</code> as <code>pd.Series</code>.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>FedPerceptron</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.datamanager</span> <span class=kn>import</span> <span class=n>DataManager</span>

<span class=k>class</span> <span class=nc>SGDRegressorTrainingPlan</span><span class=p>(</span><span class=n>FedPerceptron</span><span class=p>):</span>
    <span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># ....</span>

    <span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>num_cols</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model_args</span><span class=p>()[</span><span class=s2>&quot;number_cols&quot;</span><span class=p>]</span>
        <span class=n>dataset</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset_path</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>delimiter</span><span class=o>=</span><span class=s1>&#39;,&#39;</span><span class=p>)</span>
        <span class=n>X</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span><span class=mi>0</span><span class=p>:</span><span class=n>num_cols</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>
        <span class=n>y</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span><span class=n>num_cols</span><span class=p>]</span>
        <span class=k>return</span> <span class=n>DataManager</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>target</span><span class=o>=</span><span class=n>y</span><span class=o>.</span><span class=n>values</span><span class=p>,</span> <span class=n>batch_size</span><span class=p>)</span>
</code></pre></div> <h2 id=preprocessing-for-data>Preprocessing for Data</h2> <p>Since the method <code>training_data</code> is defined by the user, it is possible to do preprocessing before creating the <code>DataManager</code> object. In the code snippet below, a preprocess for normalization is shown for the dataset MNIST.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.dataset</span> <span class=kn>import</span> <span class=n>MnistDataset</span>

<span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
    <span class=c1># Custom torch Dataloader for MNIST data</span>
    <span class=n>transform</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>((</span><span class=mf>0.1307</span><span class=p>,),</span> <span class=p>(</span><span class=mf>0.3081</span><span class=p>,))])</span>
    <span class=n>dataset_mnist</span> <span class=o>=</span> <span class=n>MnistDataset</span><span class=p>(</span><span class=n>transform</span><span class=o>=</span><span class=n>transform</span><span class=p>,</span> <span class=n>target_transform</span><span class=o>=</span><span class=n>transform</span><span class=p>)</span>
    <span class=n>train_kwargs</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;batch_size&#39;</span><span class=p>:</span> <span class=n>batch_size</span><span class=p>,</span> <span class=s1>&#39;shuffle&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}</span>
    <span class=k>return</span> <span class=n>DataManager</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>dataset_mnist</span><span class=p>,</span> <span class=o>**</span><span class=n>train_kwargs</span><span class=p>)</span>
</code></pre></div> <div class="admonition info"> <p>Training and validation partitions are created on the node side using returned <code>DataManager</code> object. Therefore, preprocessing in <code>training_data</code> will be applied for both validation and training data.</p> </div> <h2 id=data-loaders>Data Loaders</h2> <p>A <code>DataLoader</code> is an iterable class that takes care of handling the logic of iterating over a certain dataset. Thus, while a <code>Dataset</code> is concerned with loading and preprocessing samples one-by-one, the <code>DataLoader</code> is responsible for:</p> <ul> <li>calling the dataset's <code>__getitem__</code> method when needed</li> <li>collating samples in a batch</li> <li>shuffling the data at every epoch</li> <li>in general, managing the actions related to iterating over a certain dataset</li> </ul> <p><code>DataLoader</code> is handled internally, so user does not instantiate it.</p> <h3 id=passing-arguments-to-data-loaders>Passing arguments to Data Loaders</h3> <div class="admonition important"> <p>All of the key-value pairs contained in the <code>loader_args</code> sub-dictionary of <a href=../experiment/#batch-size-and-other-loader-arguments><code>training_args</code></a> are passed as keyword arguments to the data loader. Additionally, any keyword arguments passed to the <code>DataManager</code> class inside the <code>training_data</code> function are also passed as keyword arguments to the data loader.</p> </div> <p>For example, the following setup:</p> <div class=highlight><pre><span></span><code><span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>TorchTrainingPlan</span><span class=p>):</span>
    <span class=c1># ....</span>
    <span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>dataset</span> <span class=o>=</span> <span class=n>MyDataset</span><span class=p>()</span>
        <span class=k>return</span> <span class=n>DataManager</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>training_args</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;loader_args&#39;</span><span class=p>:</span> <span class=p>{</span>
        <span class=s1>&#39;batch_size&#39;</span><span class=p>:</span> <span class=mi>5</span><span class=p>,</span>
        <span class=s1>&#39;drop_last&#39;</span><span class=p>:</span> <span class=kc>True</span>
    <span class=p>}</span>
<span class=p>}</span>
</code></pre></div> <p>Leads to the following data loader definition:</p> <div class=highlight><pre><span></span><code><span class=n>loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>drop_last</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div> <div class="admonition warning"> <p class=admonition-title>Double-specified loader arguments</p> <p>Keyword arguments passed to the <code>DataManager</code> class take precedence over arguments with the same name provided in the <code>loader_args</code> dictionary.</p> </div> <p>For PyTorch and scikit-learn experiments, the <code>DataLoaders</code> have been heavily inspired by the <a href=https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader><code>torch.utils.data.DataLoader</code></a> class, so please refer to that documentation for the meaning of the supported keyword arguments.</p> <h2 id=data-format-in-training-plan>Data Format in Training Plan</h2> <p>Training and testing data returned by the <code>DataLoader</code> is handled to the training plan in a framework-specific way:</p> <ul> <li>for PyTorch training plan, data is received via the <code>data</code> and <code>target</code> arguments of the <code>training_step</code> / <code>testing_step</code> methods of the training plan</li> <li>for SkLearn training plan, data is directly consumed to train and test the ML model (no user method)</li> </ul> <div class=highlight><pre><span></span><code><span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>TorchTrainingPlan</span><span class=p>):</span>
    <span class=c1># ...</span>
    <span class=k>def</span> <span class=nf>training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>):</span>
        <span class=c1># ....</span>
    <span class=k>def</span> <span class=nf>testing_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>):</span>
        <span class=c1># ....</span>
</code></pre></div> <p>This paragraph describes the format of the training plan data batches. For details about the data format preprocessing refer to the <a href=../../datasets/applying-transformations/ >Applying Transformations</a> documentation.</p> <p>Training plan data format and preprocessing concerns the user for 2 main reasons:</p> <ul> <li>know which format are <code>data</code> and <code>target</code> in <code>training_step</code> and <code>testing_step</code>, in the case of PyTorch training plan</li> <li>know which format needs to be delivered to the <code>DataManager</code> in the <code>training_data</code> function, for each training plan framework</li> </ul> <h3 id=batches-of-data-sample>Batches of data sample</h3> <p><code>data</code> and <code>target</code> are delivered as <strong>batches</strong> to the training plan. Each batch is a list of (at most) <code>batch_size</code> data samples.</p> <p>Each data sample is composed of a <code>data</code> and a <code>target</code> <strong>entry</strong>. If <code>target</code> is <code>None</code>, then it means there is no target in this dataset's data samples, for example for unsupervised learning.</p> <div class="admonition warning"> <p class=admonition-title>Target is needed for PyTorch</p> <p>In current Fed-BioMed version, <code>target</code> is needed for PyTorch training plan (it cannot be <code>None</code>) Workaround for dataset without target data is to add dummy target values in the dataset.</p> </div> <table> <thead> <tr> <th>Framework</th> <th>data != None</th> <th>target != None</th> <th>target == None</th> </tr> </thead> <tbody> <tr> <td>PyTorch</td> <td></td> <td></td> <td><img alt= class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/274c.svg title=:x:></td> </tr> <tr> <td>SkLearn</td> <td></td> <td></td> <td></td> </tr> </tbody> </table> <h3 id=entries-structure-and-modalities-in-a-data-sample>Entries structure and modalities in a data sample</h3> <p>Then each <code>data</code> or <code>target</code> entry needs to be:</p> <ul> <li>either monomodal: a data <strong>structure</strong> as expected by the framework</li> <li>or multimodal: a <strong>dict</strong> indexed by <code>str</code> (name of the modality) where each value is a data structure as expected by the framework</li> </ul> <table> <thead> <tr> <th>Framework</th> <th>data structure</th> <th>dict of data structure</th> </tr> </thead> <tbody> <tr> <td>PyTorch</td> <td><code>torch.Tensor</code></td> <td><code>Dict[str, torch.Tensor]</code></td> </tr> <tr> <td>SkLearn</td> <td><code>np.ndarray</code></td> <td><code>Dict[str, np.ndarray]</code> with 1 modality</td> </tr> </tbody> </table> <div class="admonition info"> <p class=admonition-title>SkLearn is monomodal in Fed-BioMed</p> <p>SkLearn support in Fed-BioMed is monomodal, to match the behaviour of most SkLearn functions. The <code>Dict</code> syntax is supported for convenience, but only <strong>one</strong> modality can exist in the <code>Dict</code>. To handle multimodal data in SkLearn, use a transformation to merge inputs from multiple modalities in a single entry.</p> </div> <p>In SkLearn, most functions require vectors (1-dimensional inputs) or values (0-dimensional inputs). To match this behaviour, <code>DataLoader</code> checks that the input <code>np.ndarray</code> passed to the SkLearn training plan has <code>ndim =&lt; 1</code>.</p> <p>!!! info "SkLearn training plan needs <code>ndim =&lt; 1</code> If the <code>Dataset</code> returns <code>np.ndarray</code> with <code>ndim &gt;= 2</code>, use a dataset transformation to flatten the data structure, as explained in <a href=../../datasets/applying-transformations/ >Applying Transformations</a> documentation.</p> <h3 id=format-of-structure-values>Format of structure values</h3> <p>Finally, each structure (<code>torch.Tensor</code>, <code>np.ndarray</code>) has values of one <strong>type</strong> (<code>dtype</code>): a <code>float</code>, an <code>int</code>. For each framework, each type has a preferred <strong>format</strong> (eg <code>float32</code>, <code>float64</code>).</p> <p>Fed-BioMed automatically assigns the preferred format for the framework before delivering the values to the training plan.</p> <table> <thead> <tr> <th>Framework</th> <th>value type</th> <th><code>dtype</code> format</th> </tr> </thead> <tbody> <tr> <td>PyTorch</td> <td>any floating point</td> <td><code>torch.get_default_dtype()</code> usually <code>torch.float32</code></td> </tr> <tr> <td>PyTorch</td> <td>any integer</td> <td><code>torch.long</code></td> </tr> <tr> <td>scikit-learn</td> <td>any <code>np.floating</code></td> <td><code>np.float64</code></td> </tr> <tr> <td>scikit-learn</td> <td>any <code>np.integer</code></td> <td><code>np.int64</code></td> </tr> </tbody> </table> <p>For example, for <code>PyTorch</code>, floating point values are delivered as <code>torch.get_default_dtype()</code> which is usually (and by default) <code>torch.float32</code></p> <h2 id=conclusion>Conclusion</h2> <p><code>training_data</code> should be provided in each training plan. The way it is defined is almost the same for each framework's training plan as long as the structure of the datasets is simple. Since the method is defined by users, it provides flexibility to load and pre-process complex datasets distributed on the nodes. However, this method will be executed on the node side. Therefore, typos and lack of arguments may cause errors in the nodes even if it does not create any errors on the researcher side.</p> </article> </main> </div> <div class=right-col> <div id=right-sidebar class=sidebar-right> <nav class=toc> <!-- Render item list --> <label class=toc-title for=__toc> <span class=toc-icon></span> </label> <ul class=toc-list data-md-component=toc data-md-scrollfix> <!-- Table of contents item --> <li class=toc-item> <a href=#defining-the-method-training-data class=md-nav__link> Defining The Method Training Data </a> <nav class=toc-nav aria-label="Defining The Method Training Data"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#the-datamanager-return-type class=md-nav__link> The DataManager return type </a> </li> </ul> </nav> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#defining-training-data-in-different-training-plans class=md-nav__link> Defining Training Data in Different Training Plans </a> <nav class=toc-nav aria-label="Defining Training Data in Different Training Plans"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#defining-training-data-for-pytorch-based-training-plans class=md-nav__link> Defining Training Data for PyTorch Based Training Plans </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#defining-training-data-for-sklearn-based-training-plans class=md-nav__link> Defining Training Data for SkLearn Based Training Plans </a> </li> </ul> </nav> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#preprocessing-for-data class=md-nav__link> Preprocessing for Data </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#data-loaders class=md-nav__link> Data Loaders </a> <nav class=toc-nav aria-label="Data Loaders"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#passing-arguments-to-data-loaders class=md-nav__link> Passing arguments to Data Loaders </a> </li> </ul> </nav> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#data-format-in-training-plan class=md-nav__link> Data Format in Training Plan </a> <nav class=toc-nav aria-label="Data Format in Training Plan"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#batches-of-data-sample class=md-nav__link> Batches of data sample </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#entries-structure-and-modalities-in-a-data-sample class=md-nav__link> Entries structure and modalities in a data sample </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#format-of-structure-values class=md-nav__link> Format of structure values </a> </li> </ul> </nav> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#conclusion class=md-nav__link> Conclusion </a> </li> </ul> </nav> </div> </div> </div> </div> <!-- News Main Page--> </div> <footer> <div class=container-fluid> <div class=footer-first-inner> <div class=container> <div class=row> <div class=col-md-6> <div class=footer-contact> <strong>Address:</strong> <p>2004 Rte des Lucioles, 06902 Sophia Antipolis</p> <strong>E-mail:</strong> <p>fedbiomed _at_ inria _dot_ fr</p> </div> </div> <div class=col-md-6> <div class=footer-contact> <p>Fed-BioMed  2022</p> </div> </div> </div> </div> </div> </div> </footer> <!-- JQuery --> <script src=https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js></script> <!-- Latest compiled and minified JavaScript --> <script src=https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js integrity=sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd crossorigin=anonymous></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/tablesort/5.2.1/tablesort.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../../assets/javascript/lunr.js></script> <script src=../../../assets/javascript/theme.js></script> <!-- GitHub buttons --> <script async defer src=https://buttons.github.io/buttons.js></script> </body> </html>