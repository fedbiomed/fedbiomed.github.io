<!DOCTYPE html><html> <head><meta charset=UTF-8><meta name=viewport content="width=device-width, initial-scale=1"><meta name=robots context="index, archive"><!--  --><script>
      const versions_json = "../../../../versions.json";
      const search_worker_js = "../../../assets/javascript/search-worker.js";
      const search_index_json = "../../../search/search_index.json";
      const base_url = '../../..';
    </script><!-- Site title --><title>Applying Transformations - Fed-BioMed</title><link rel=icon type=image/x-icon href=../../../favicon.ico><!-- Page description --><meta name=description content="Open, Transparent and Trusted Collaborative Learning for Real-world Healthcare Applications"><!-- Page keywords --><!-- Page author --><!-- Latest compiled and minified CSS --><link rel=stylesheet href=https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css integrity=sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu crossorigin=anonymous><!-- Bootstrap Icons --><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css><link href=../../../assets/_mkdocstrings.css rel=stylesheet><link href=../../../assets/css/style.css rel=stylesheet></head> <body> <header> <div class="container-fluid top-bar"> <div class=brand> <a href=/ > <img src=../../../assets/img/fedbiomed-logo-small.png> </a> </div> <nav class=top> <ul> <li class> <a href=../../..>Home</a> </li> <li class> <a href=../../../getting-started/what-is-fedbiomed/ >User Documentation</a> </li> <li class> <a href=../../../pages/about-us/ >About</a> </li> <li id=clicker class=has-sub> More <i class="bi bi-chevron-down"></i> <ul class=sub-nav-menu> <li class> <a href=../../../#funding>Funding</a> </li> <li class> <a href=../../../news/ >News</a> </li> <li class> <a href=../../../#contributors>Contributors</a> </li> <li class> <a href=../../../#users>Users</a> </li> <li class> <a href=../../../pages/roadmap/ >Roadmap</a> </li> <li class> <a href=../../../#citation>How to Cite Us</a> </li> <li class> <a href=../../../#contact-us>Contact Us</a> </li> </ul> </li> </ul> </nav> </div> <div class="container-fluid top-bar-mobile"> <div class=mobile-bar> <div class=brand> <a href=../../../ > <img src=../../../assets/img/fedbiomed-logo-small.png> </a> </div> <div class=hum-menu> <img class=open src=../../../assets/img/menu.svg> <img class=close style=display:none src=../../../assets/img/cancel.svg> </div> </div> <nav class=top-mobile> <ul> <li class> <a href=../../..>Home</a> </li> <li class> <a href=../../../getting-started/what-is-fedbiomed/ >User Documentation</a> </li> <li class> <a href=../../../pages/about-us/ >About</a> </li> <li id=clicker class=has-sub> More <i class="bi bi-chevron-down"></i> <ul class=sub-nav-menu> <li class> <a href=../../../#funding>Funding</a> </li> <li class> <a href=../../../news/ >News</a> </li> <li class> <a href=../../../#contributors>Contributors</a> </li> <li class> <a href=../../../#users>Users</a> </li> <li class> <a href=../../../pages/roadmap/ >Roadmap</a> </li> <li class> <a href=../../../#citation>How to Cite Us</a> </li> <li class> <a href=../../../#contact-us>Contact Us</a> </li> </ul> </li> </ul> </nav> </div> </header> <div class=main> <!-- Home page --> <div class=container-fluid> <div class=doc-row> <div class=left-col> <div class=sidebar-doc> <nav class=sidebar-inner> <ul class="sidebar-menu-left sub"> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Getting Started <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../getting-started/what-is-fedbiomed/ class>What's Fed-BioMed</a> </li> <li class> <a href=../../../getting-started/fedbiomed-architecture/ class>Fedbiomed Architecture</a> </li> <li class> <a href=../../../getting-started/fedbiomed-workflow/ class>Fedbiomed Workflow</a> </li> <li class> <a href=../../../getting-started/installation/ class>Installation</a> </li> <li class> <a href=../../../getting-started/basic-example/ class>Basic Example</a> </li> <li class> <a href=../../../getting-started/configuration/ class>Configuration</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Tutorials <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> PyTorch <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/pytorch/01_PyTorch_MNIST_Single_Node_Tutorial/ class>PyTorch MNIST Basic Example</a> </li> <li class> <a href=../../../tutorials/pytorch/02_Create_Your_Custom_Training_Plan/ class>How to Create Your Custom PyTorch Training Plan</a> </li> <li class> <a href=../../../tutorials/pytorch/03_PyTorch_Used_Cars_Dataset_Example/ class>PyTorch Used Cars Dataset Example</a> </li> <li class> <a href=../../../tutorials/pytorch/05_Transfer-learning_tutorial_usingDenseNet-121/ class>Transfer-learning in Fed-BioMed tutorial</a> </li> <li class> <a href=../../../tutorials/pytorch/04-Aggregation_in_Fed-BioMed/ class>PyTorch aggregation methods in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> MONAI <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/monai/01_monai-2d-image-classification/ class>Federated 2d image classification with MONAI</a> </li> <li class> <a href=../../../tutorials/monai/02_monai-2d-image-registration/ class>Federated 2d XRay registration with MONAI</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Scikit-Learn <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/scikit-learn/01_sklearn_MNIST_classification_tutorial/ class>MNIST classification with Scikit-Learn Classifier (Perceptron)</a> </li> <li class> <a href=../../../tutorials/scikit-learn/02_sklearn_sgd_regressor_tutorial/ class>Fed-BioMed to train a federated SGD regressor model</a> </li> <li class> <a href=../../../tutorials/scikit-learn/03-other-scikit-learn-models/ class>Implementing other Scikit Learn models for Federated Learning</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Optimizers <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/optimizers/01-fedopt-and-scaffold/ class>Advanced optimizers in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> FLamby <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/flamby/ class>Introduction</a> </li> <li class> <a href=../../../tutorials/flamby/flamby-integration-into-fedbiomed/ class>FLamby in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Advanced <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/advanced/in-depth-experiment-configuration/ class>In Depth Experiment Configuration</a> </li> <li class> <a href=../../../tutorials/advanced/training-with-gpu/ class>PyTorch model training using a GPU</a> </li> <li class> <a href=../../../tutorials/advanced/breakpoints/ class>Breakpoints</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Security <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/security/differential-privacy-with-opacus-on-fedbiomed/ class>Using Differential Privacy with OPACUS on Fed-BioMed</a> </li> <li class> <a href=../../../tutorials/security/non-private-local-central-dp-monai-2d-image-registration/ class>Local and Central DP with Fed-BioMed: MONAI 2d image registration</a> </li> <li class> <a href=../../../tutorials/security/training-with-approved-training-plans/ class>Training Process with Training Plan Management</a> </li> <li class> <a href=../../../tutorials/security/secure-aggregation/ class>Training with Secure Aggregation</a> </li> <li class> <a href=../../../tutorials/concrete-ml/concrete-ml/ class>End-to-end Privacy Preserving Training and Inference on Medical Data</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Biomedical data <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/medical/medical-image-segmentation-unet-library/ class>Brain Segmentation</a> </li> </ul> </li> </ul> </li> <li data-adress=sub-1 class="current has-sub-side"> <div href class="parent-list current "> User Guide <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub active "> <li class> <a href=../../glossary/ class>Glossary</a> </li> <li data-adress=sub-1 class="current has-sub-side"> <div href class="parent-list current "> Datasets <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub active "> <li class> <a href=../ class>Introduction</a> </li> <li class> <a href=../default-datasets/ class>Default Datasets</a> </li> <li class> <a href=../image-dataset/ class>Image Datasets</a> </li> <li class> <a href=../tabular-dataset/ class>Tabular Datasets</a> </li> <li class> <a href=../medical-folder-dataset/ class>Medical Datasets</a> </li> <li class> <a href=../custom-dataset/ class>Adding your Custom Dataset</a> </li> <li class> <a href=../native-dataset/ class>Adding a Native Dataset</a> </li> <li class=current> <a href=./ class="link current">Applying Transformations</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Deployment <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../deployment/deployment/ class>Introduction</a> </li> <li class> <a href=../../deployment/deployment-vpn/ class>VPN Deployment</a> </li> <li class> <a href=../../deployment/matrix/ class>Network matrix</a> </li> <li class> <a href=../../deployment/security-model/ class>Security model</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Node <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../nodes/configuring-nodes/ class>Configuring Nodes</a> </li> <li class> <a href=../../nodes/deploying-datasets/ class>Deploying Datasets</a> </li> <li class> <a href=../../nodes/training-plan-security-manager/ class>Training Plan Management</a> </li> <li class> <a href=../../nodes/using-gpu/ class>Using GPU</a> </li> <li class> <a href=../../nodes/node-gui/ class>Node GUI</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Researcher <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../researcher/training-plan/ class>Training Plan</a> </li> <li class> <a href=../../researcher/training-data/ class>Training Data</a> </li> <li class> <a href=../../researcher/experiment/ class>Experiment</a> </li> <li class> <a href=../../researcher/aggregation/ class>Aggregation</a> </li> <li class> <a href=../../researcher/listing-datasets-and-selecting-nodes/ class>Listing Datasets and Selecting Nodes</a> </li> <li class> <a href=../../researcher/model-testing-during-federated-training/ class>Model Validation on the Node Side</a> </li> <li class> <a href=../../researcher/tensorboard/ class>Tensorboard</a> </li> </ul> </li> <li class> <a href=../../advanced-optimization/ class>Optimization</a> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Secure Aggregation <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../secagg/introduction/ class>Introduction</a> </li> <li class> <a href=../../secagg/configuration/ class>Configuration</a> </li> <li class> <a href=../../secagg/researcher-interface/ class>Managing Secure Aggregation in Researcher</a> </li> </ul> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Developer <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> API Reference <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Common <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../developer/api/common/certificate_manager/ class>Certificate Manager</a> </li> <li class> <a href=../../../developer/api/common/cli/ class>CLI</a> </li> <li class> <a href=../../../developer/api/common/config/ class>Config</a> </li> <li class> <a href=../../../developer/api/common/constants/ class>Constants</a> </li> <li class> <a class href=../../../developer/api/common/data.md>Data</a> </li> <li class> <a href=../../../developer/api/common/db/ class>DB</a> </li> <li class> <a href=../../../developer/api/common/exceptions/ class>Exceptions</a> </li> <li class> <a href=../../../developer/api/common/ipython/ class>IPython</a> </li> <li class> <a href=../../../developer/api/common/json/ class>Json</a> </li> <li class> <a href=../../../developer/api/common/logger/ class>Logger</a> </li> <li class> <a href=../../../developer/api/common/message/ class>Message</a> </li> <li class> <a href=../../../developer/api/common/metrics/ class>Metrics</a> </li> <li class> <a href=../../../developer/api/common/models/ class>Model</a> </li> <li class> <a class href=../../../developer/api/common/mpc_controller.md>MPC controller</a> </li> <li class> <a href=../../../developer/api/common/optimizers/ class>Optimizers</a> </li> <li class> <a href=../../../developer/api/common/privacy/ class>Privacy</a> </li> <li class> <a href=../../../developer/api/common/secagg/ class>Secagg</a> </li> <li class> <a href=../../../developer/api/common/secagg_manager/ class>Secagg Manager</a> </li> <li class> <a href=../../../developer/api/common/serializer/ class>Serializer</a> </li> <li class> <a href=../../../developer/api/common/singleton/ class>Singleton</a> </li> <li class> <a href=../../../developer/api/common/synchro/ class>Synchro</a> </li> <li class> <a href=../../../developer/api/common/tasks_queue/ class>TasksQueue</a> </li> <li class> <a href=../../../developer/api/common/training_plans/ class>TrainingPlans</a> </li> <li class> <a href=../../../developer/api/common/training_args/ class>TrainingArgs</a> </li> <li class> <a href=../../../developer/api/common/utils/ class>Utils</a> </li> <li class> <a href=../../../developer/api/common/validator/ class>Validator</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Node <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../developer/api/node/cli/ class>CLI</a> </li> <li class> <a href=../../../developer/api/node/cli_utils/ class>CLI Utils</a> </li> <li class> <a href=../../../developer/api/node/config/ class>Config</a> </li> <li class> <a href=../../../developer/api/node/dataset_manager/ class>DatasetManager</a> </li> <li class> <a href=../../../developer/api/node/history_monitor/ class>HistoryMonitor</a> </li> <li class> <a href=../../../developer/api/node/node/ class>Node</a> </li> <li class> <a href=../../../developer/api/node/node_state_manager/ class>NodeStateManager</a> </li> <li class> <a href=../../../developer/api/node/requests/ class>Requests</a> </li> <li class> <a href=../../../developer/api/node/round/ class>Round</a> </li> <li class> <a href=../../../developer/api/node/secagg/ class>Secagg</a> </li> <li class> <a href=../../../developer/api/node/secagg_manager/ class>Secagg Manager</a> </li> <li class> <a href=../../../developer/api/node/training_plan_security_manager/ class>TrainingPlanSecurityManager</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Researcher <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../developer/api/researcher/aggregators/ class>Aggregators</a> </li> <li class> <a href=../../../developer/api/researcher/cli/ class>CLI</a> </li> <li class> <a href=../../../developer/api/researcher/config/ class>Config</a> </li> <li class> <a href=../../../developer/api/researcher/datasets/ class>Datasets</a> </li> <li class> <a href=../../../developer/api/researcher/federated_workflows/ class>Federated Workflows</a> </li> <li class> <a href=../../../developer/api/researcher/filetools/ class>Filetools</a> </li> <li class> <a href=../../../developer/api/researcher/jobs/ class>Jobs</a> </li> <li class> <a href=../../../developer/api/researcher/monitor/ class>Monitor</a> </li> <li class> <a href=../../../developer/api/researcher/node_state_agent/ class>NodeStateAgent</a> </li> <li class> <a href=../../../developer/api/researcher/requests/ class>Requests</a> </li> <li class> <a href=../../../developer/api/researcher/secagg/ class>Secagg</a> </li> <li class> <a href=../../../developer/api/researcher/strategies/ class>Strategies</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Transport <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../developer/api/transport/client/ class>Client</a> </li> <li class> <a href=../../../developer/api/transport/controller/ class>Controller</a> </li> <li class> <a href=../../../developer/api/transport/node_agent/ class>NodeAgent</a> </li> <li class> <a href=../../../developer/api/transport/server/ class>Server</a> </li> </ul> </li> </ul> </li> <li class> <a href=../../../developer/usage_and_tools/ class>Usage and Tools</a> </li> <li class> <a href=../../../developer/ci/ class>Continuous Integration</a> </li> <li class> <a href=../../../developer/definition-of-done/ class>Definition of Done</a> </li> <li class> <a href=../../../developer/development-environment/ class>Development Environment</a> </li> <li class> <a href=../../../developer/testing-in-fedbiomed/ class>Testing in Fed-BioMed</a> </li> <li class> <a href=../../../developer/messaging/ class>RPC Protocol and Messages</a> </li> </ul> </li> <li class> <a href=../../../support/troubleshooting/ class>FAQ & Troubleshooting</a> </li> </ul> </nav> </div> </div> <div class=main-col> <main class=main-docs> <article> <h1 id=applying-transformations>Applying Transformations</h1> <h2 id=introduction>Introduction</h2> <p>Transformations are custom functions that preprocess your data before training. You can use them to normalize images, scale tabular features, perform data augmentation, and many other preprocessing tasks. Transformations are defined in the <code>TrainingPlan</code> as dataset parameters, and Fed-BioMed automatically applies them on each node during data loading. This guide explains how to write transform functions that work with different data types and machine learning frameworks.</p> <h2 id=transform-pipeline-overview>Transform Pipeline Overview</h2> <p>Fed-BioMed's transformation pipeline consists of distinct stages, with <strong>user transforms</strong> being the primary customization point:</p> <div class=highlight><pre><span></span><code>Raw Data â†’ Node Processing â†’ Framework Conversion â†’ Default Format â†’ ðŸŽ¯ User Transforms â†’ Default Format â†’ ML Framework
    â”‚            â”‚                   â”‚                    â”‚                    â”‚                â”‚              â”‚
Files/DB    Standardized       Framework-Ready      Framework-Ready       Customized      Framework-Ready    Training
            Format             Types                Type Formats          Processing      Type Formats       Ready
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Key Points</p> <ul> <li><strong>What you control</strong>: Custom preprocessing, augmentation, normalization logic, etc.</li> <li><strong>What Fed-BioMed handles</strong>: Data loading and framework conversion.</li> <li><strong>Your responsibility</strong>: Ensure transforms respect framework type requirements:<ul> <li><strong>PyTorch</strong>: Input/output <code>torch.Tensor</code> </li> <li><strong>Scikit-learn</strong>: Input/output <code>numpy.ndarray</code></li> </ul> </li> </ul> </div> <h2 id=data-types-and-transform-requirements>Data Types and Transform Requirements</h2> <p>This section details what data the node provides and what your transforms should expect as input/output for each framework.</p> <p><strong>Node Data â†’ Framework Conversion â†’ Default Format â†’ Transform Input</strong></p> <p>The table below illustrates Fed-BioMed's automatic data conversion pipeline. <strong>Before your custom transform function is called</strong>, Fed-BioMed automatically converts the node-provided data into framework-appropriate types. Then the default formats are applied to data.</p> <table> <thead> <tr> <th>Dataset Type</th> <th>Node Data Format</th> <th><strong>Fed-BioMed converts to â†’</strong> PyTorch Input</th> <th><strong>Fed-BioMed converts to â†’</strong> Scikit-learn Input</th> </tr> </thead> <tbody> <tr> <td><strong>Tabular</strong></td> <td><code>polars.DataFrame</code></td> <td><code>torch.Tensor</code></td> <td><code>numpy.ndarray</code></td> </tr> <tr> <td><strong>Medical</strong></td> <td><code>dict</code> of <code>nibabel.Nifti1Image</code> + <code>dict</code> (demographics)</td> <td><code>Dict[str, torch.Tensor]</code></td> <td><code>Dict[str, numpy.ndarray]</code></td> </tr> <tr> <td><strong>Image</strong></td> <td><code>PIL.Image.Image</code></td> <td><code>torch.Tensor (C, H, W) [0-1]</code></td> <td><code>numpy.ndarray (H, W, C) [0-255]</code></td> </tr> <tr> <td><strong>Native/Custom</strong></td> <td>Variable</td> <td><code>torch.Tensor</code> (best-effort conversion)</td> <td><code>numpy.ndarray</code> (best-effort conversion)</td> </tr> </tbody> </table> <p>After converting data to framework-appropriate types, Fed-BioMed changes data type formats. Each framework has a preferred format (<code>dtype</code>) for each data type (floats, integers). For example, PyTorch usually handles floats as <code>torch.float32</code>. The default format step converts data to the preferred format for this type, in the framework used by the training plan. For example, for a PyTorch training plan, integers are converted to <code>torch.long</code> integers. The data type is not changed (eg: floats remain some format of floats). This ensures your transform receives the data in some predictable format, adapted to the training plan framework used. Your transform function then receives this default typed and formatted data as input.</p> <table> <thead> <tr> <th>Framework</th> <th>Data type</th> <th>Source <code>dtype</code></th> <th><strong>Fed-BioMed changes to</strong> <code>dtype</code></th> </tr> </thead> <tbody> <tr> <td>PyTorch</td> <td><code>torch.Tensor</code></td> <td>any floating point</td> <td><code>torch.get_default_dtype()</code> usually <code>torch.float32</code></td> </tr> <tr> <td>PyTorch</td> <td><code>torch.Tensor</code></td> <td>any integer</td> <td><code>torch.long</code></td> </tr> <tr> <td>scikit-learn</td> <td><code>np.ndarray</code></td> <td>any <code>np.floating</code></td> <td><code>np.float64</code></td> </tr> <tr> <td>scikit-learn</td> <td><code>np.ndarray</code></td> <td>any <code>np.integer</code></td> <td><code>np.int64</code></td> </tr> </tbody> </table> <p>Default format conversion does effective data conversion only if the source format changes, so it avoid the memory and computing cost of useless conversions.</p> <div class="admonition note"> <p class=admonition-title>Understanding the conversion process</p> <ul> <li><strong>Node Data Format</strong>: The data format provided by Fed-BioMed nodes after loading and initial processing</li> <li><strong>Fed-BioMed Auto-Conversion</strong>: Fed-BioMed automatically applies framework-specific conversions before calling your transform (e.g., <code>DataFrame.to_torch()</code> for PyTorch, <code>DataFrame.to_numpy()</code> for scikit-learn), plus the default format conversions.</li> <li><strong>Your Transform Input</strong>: The converted data type that your custom transform function will receive and must handle</li> </ul> </div> <p><strong>Transform Output Requirements</strong></p> <p>The output format of your custom transform function is <strong>crucial</strong> and differs significantly between frameworks. Understanding these requirements is essential for successful federated learning implementation.</p> <div class="admonition warning"> <p class=admonition-title>Framework Output Requirements</p> <ul> <li><strong>PyTorch</strong>: Can handle flexible output structures (<code>torch.Tensor</code> or <code>Dict[str, torch.Tensor]</code>) because the model's method <code>training_step</code> can organize data as needed.</li> <li><strong>Scikit-learn</strong>: Requires <strong>flattened arrays only</strong> (<code>numpy.ndarray</code>) - the exact format the ML model will consume. No dictionaries or complex structures are allowed.</li> </ul> </div> <p>The default format conversion step (see above) is applied again after the custom transform function, to ensure the training plan receives data in the preferred format. Yet, unless needed, it is a good practice to keep the <code>dtype</code> of data. </p> <h2 id=common-transform-operations>Common Transform Operations</h2> <div class="admonition note"> <p class=admonition-title>Key Constraint</p> <p>Transforms operate on individual samples without access to global dataset statistics. Use pre-defined constants from domain knowledge instead of computed statistics.</p> </div> <p><strong>General Patterns:</strong></p> <ul> <li><strong>Normalization</strong>: Use known constants like <code>(data - known_mean) / known_std</code> or simple scaling <code>data / max_value</code></li> <li><strong>Scaling</strong>: Apply min-max with known ranges <code>(data - min_val) / (max_val - min_val)</code> or standardization to 0-1</li> <li><strong>Augmentation</strong>: Use sample-level transforms like rotations, flips, noise addition with fixed parameters</li> <li><strong>Feature Engineering</strong>: Create polynomial features, one-hot encoding, or domain-specific transformations</li> <li><strong>Clipping</strong>: Apply bounds with <code>torch.clamp()</code> or <code>np.clip()</code> using known value ranges</li> </ul> <p><strong>Data-Type Specific Examples:</strong></p> <ul> <li><strong>Tabular</strong>: Feature scaling, categorical encoding, log transforms for count data</li> <li><strong>Images</strong>: Resizing, intensity normalization (e.g., ImageNet constants), geometric augmentation </li> <li><strong>Medical</strong>: Protocol-specific normalization, conservative augmentation preserving clinical features, multi-modal combination</li> </ul> <h2 id=writing-transform-functions>Writing Transform Functions</h2> <p>This section provides complete code examples showing how to write transform functions for different data types. Each example demonstrates the input types you'll receive, the processing you can apply, and the output formats required by each framework.</p> <p><strong>Tabular Data Transforms:</strong></p> <p>Tabular transforms handle individual samples from structured datasets. Each transform receives a single row of features as input.</p> <div class=highlight><pre><span></span><code><span class=c1># PyTorch tabular transform</span>
<span class=k>def</span> <span class=nf>tabular_pytorch_transform</span><span class=p>(</span><span class=n>data</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
    <span class=c1># Input: torch.Tensor (float32) - numerical/categorical features</span>
    <span class=c1># Output: torch.Tensor</span>
    <span class=n>processed_features</span> <span class=o>=</span> <span class=n>preprocess</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

    <span class=c1># Simple tensor output</span>
    <span class=k>return</span> <span class=n>processed_features</span>

<span class=c1># Scikit-learn tabular transform </span>
<span class=k>def</span> <span class=nf>tabular_sklearn_transform</span><span class=p>(</span><span class=n>data</span><span class=p>:</span> <span class=n>numpy</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>numpy</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
    <span class=c1># Input: numpy.ndarray (float64) - numerical/categorical features</span>
    <span class=c1># Output: numpy.ndarray (MUST be flattened, ready for sklearn model)</span>
    <span class=n>processed</span> <span class=o>=</span> <span class=n>preprocess</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>processed</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span> <span class=k>if</span> <span class=n>processed</span><span class=o>.</span><span class=n>ndim</span> <span class=o>&gt;</span> <span class=mi>1</span> <span class=k>else</span> <span class=n>processed</span>
</code></pre></div> <p><strong>Medical Image Transforms:</strong></p> <p>Medical transforms work with multi-modal data combining imaging (MRI, CT) and demographic information.</p> <div class=highlight><pre><span></span><code><span class=c1># PyTorch medical transforms - ALWAYS receive Dict[str, torch.Tensor]</span>
<span class=c1># OUTPUT OPTIONS: Multiple formats supported</span>
<span class=k>def</span> <span class=nf>medical_pytorch_transform</span><span class=p>(</span><span class=n>data</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>Union</span><span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>]]:</span>
    <span class=c1># Input - medical data modalities</span>

    <span class=c1># OPTION 1: Preserve original modality structure</span>
    <span class=k>def</span> <span class=nf>option1_preserve_modalities</span><span class=p>():</span>
        <span class=n>processed</span> <span class=o>=</span> <span class=p>{}</span>
        <span class=k>for</span> <span class=n>modality_name</span><span class=p>,</span> <span class=n>tensor</span> <span class=ow>in</span> <span class=n>data</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
            <span class=k>if</span> <span class=n>modality_name</span> <span class=o>==</span> <span class=s1>&#39;demographics&#39;</span><span class=p>:</span>
                <span class=n>processed</span><span class=p>[</span><span class=n>modality_name</span><span class=p>]</span> <span class=o>=</span> <span class=n>process_demographics</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>processed</span><span class=p>[</span><span class=n>modality_name</span><span class=p>]</span> <span class=o>=</span> <span class=n>apply_medical_preprocessing</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>processed</span>  <span class=c1># Dict[str, torch.Tensor]</span>

    <span class=c1># OPTION 2: Return single tensor (any dimensions supported)</span>
    <span class=k>def</span> <span class=nf>option2_single_tensor</span><span class=p>():</span>
        <span class=c1># flattened and combined</span>
        <span class=n>all_features</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=k>for</span> <span class=n>modality_name</span><span class=p>,</span> <span class=n>tensor</span> <span class=ow>in</span> <span class=n>data</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
            <span class=n>processed</span> <span class=o>=</span> <span class=n>apply_medical_preprocessing</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span>
            <span class=n>all_features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>processed</span><span class=o>.</span><span class=n>flatten</span><span class=p>())</span>
        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>all_features</span><span class=p>)</span>  <span class=c1># [combined_features]</span>

        <span class=c1># stacked modalities  </span>
        <span class=n>imaging_tensors</span> <span class=o>=</span> <span class=p>[</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;T1&#39;</span><span class=p>],</span> <span class=n>data</span><span class=p>[</span><span class=s1>&#39;T2&#39;</span><span class=p>]]</span>
        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>imaging_tensors</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># [2, C, H, W]</span>

    <span class=c1># Choose any option - train_step handles all formats</span>
    <span class=k>return</span> <span class=n>option1_preserve_modalities</span><span class=p>()</span>  <span class=c1># option2_single_tensor()</span>

<span class=c1># Scikit-learn medical transform - receives Dict but MUST return flattened array</span>
<span class=k>def</span> <span class=nf>medical_sklearn_transform</span><span class=p>(</span><span class=n>data</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>numpy</span><span class=o>.</span><span class=n>ndarray</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>numpy</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
    <span class=c1># Input: Dict[str, numpy.ndarray] - medical data modalities</span>
    <span class=c1># Output: numpy.ndarray (MUST be single flattened 1D array combining all modalities)</span>

    <span class=n>all_features</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>modality_name</span><span class=p>,</span> <span class=n>array</span> <span class=ow>in</span> <span class=n>data</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
        <span class=k>if</span> <span class=n>modality_name</span> <span class=o>==</span> <span class=s1>&#39;demographics&#39;</span><span class=p>:</span>
            <span class=c1># Handle demographic data</span>
            <span class=n>demo_features</span> <span class=o>=</span> <span class=n>process_demographics</span><span class=p>(</span><span class=n>array</span><span class=p>)</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
            <span class=n>all_features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>demo_features</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># Handle imaging modalities - flatten each</span>
            <span class=n>img_features</span> <span class=o>=</span> <span class=n>apply_medical_preprocessing</span><span class=p>(</span><span class=n>array</span><span class=p>)</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
            <span class=n>all_features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>img_features</span><span class=p>)</span>

    <span class=c1># ONLY option: single flattened array</span>
    <span class=k>return</span> <span class=n>numpy</span><span class=o>.</span><span class=n>concatenate</span><span class=p>(</span><span class=n>all_features</span><span class=p>)</span>  <span class=c1># [all_features_combined]</span>
</code></pre></div> <p><strong>Image Transforms:</strong></p> <p>Standard image transforms handle computer vision data, from PIL images converted to either tensors or arrays and with different value ranges and shapes in each case.</p> <div class=highlight><pre><span></span><code><span class=c1># PyTorch image transforms</span>
<span class=k>def</span> <span class=nf>image_pytorch_transform</span><span class=p>(</span><span class=n>data</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
    <span class=c1># Input: torch.Tensor [C, H, W] values 0-1 - PIL converted to tensor</span>
    <span class=c1># Output: torch.Tensor</span>
    <span class=n>processed</span> <span class=o>=</span> <span class=n>apply_image_preprocessing</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

    <span class=c1># Simple tensor or complex dictionary both work</span>
    <span class=k>return</span> <span class=n>processed</span>  <span class=c1># or return {&quot;image&quot;: processed, &quot;augmented&quot;: augmented_version}</span>

<span class=c1># Scikit-learn image transforms</span>
<span class=k>def</span> <span class=nf>image_sklearn_transform</span><span class=p>(</span><span class=n>data</span><span class=p>:</span> <span class=n>numpy</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>numpy</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
    <span class=c1># Input: numpy.ndarray [H, W, C] values 0-255 - PIL as array</span>
    <span class=c1># Output: numpy.ndarray (MUST be flattened 1D array for sklearn model)</span>
    <span class=n>processed</span> <span class=o>=</span> <span class=n>apply_image_preprocessing</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>processed</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>  <span class=c1># Always flatten for sklearn</span>
</code></pre></div> <p><strong>Native/Custom Dataset Transforms:</strong></p> <p>Native transforms handle custom data formats that don't fit standard categories. Fed-BioMed attempts automatic conversion but may need manual handling.</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>flexible_pytorch_transform</span><span class=p>(</span><span class=n>data</span><span class=p>:</span> <span class=n>Any</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Union</span><span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>]]:</span>
    <span class=c1># Input: Variable type (depends on source dataset)</span>
    <span class=c1># Output: torch.Tensor OR Dict[str, torch.Tensor] (train_step handles both)</span>
    <span class=n>processed</span> <span class=o>=</span> <span class=n>convert_and_process</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
    <span class=c1># Can return complex structures</span>
    <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;processed&quot;</span><span class=p>:</span> <span class=n>processed</span><span class=p>,</span> <span class=s2>&quot;metadata&quot;</span><span class=p>:</span> <span class=n>extract_metadata</span><span class=p>(</span><span class=n>data</span><span class=p>)}</span>

<span class=k>def</span> <span class=nf>flexible_sklearn_transform</span><span class=p>(</span><span class=n>data</span><span class=p>:</span> <span class=n>Any</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>numpy</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
    <span class=c1># Input: Variable type (depends on source dataset)  </span>
    <span class=c1># Output: numpy.ndarray (MUST be flattened 1D array)</span>
    <span class=n>processed</span> <span class=o>=</span> <span class=n>convert_and_process</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>numpy</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>processed</span><span class=p>)</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>  <span class=c1># Always flatten for sklearn</span>
</code></pre></div> <h2 id=using-transforms-in-training-plans>Using Transforms in Training Plans</h2> <p>Transforms are applied through dataset configuration within Training Plans. The dataset's parameters <code>transform</code> and <code>target_transform</code> accept your custom transformation functions, which Fed-BioMed calls automatically during data loading.</p> <p><strong>Training Plan Setup:</strong> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>my_custom_transform</span><span class=p>(</span><span class=n>data</span><span class=p>):</span>
    <span class=c1># Fed-BioMed ensures input matches framework expectations</span>
    <span class=c1># Apply your preprocessing logic</span>
    <span class=k>return</span> <span class=n>processed_data</span>  <span class=c1># Must match framework output requirements</span>
<span class=o>...</span>
<span class=c1># In your Training Plan</span>
<span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
    <span class=n>dataset</span> <span class=o>=</span> <span class=n>MyDataset</span><span class=p>(</span>
        <span class=n>transform</span><span class=o>=</span><span class=n>my_custom_transform</span><span class=p>,</span>  <span class=c1># Your transform function</span>
        <span class=n>target_transform</span><span class=o>=</span><span class=n>my_target_transform</span>  <span class=c1># Optional target transform</span>
    <span class=p>)</span>
    <span class=k>return</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>)</span>
</code></pre></div></p> <div class="admonition note"> <p class=admonition-title>Key Points</p> <ul> <li><strong>One transform per data item</strong>: 'data' and 'target' handle independent transforms</li> <li><strong>Automatic execution</strong>: Fed-BioMed calls your transforms on each data sample</li> <li><strong>Framework consistency</strong>: Same transform works across all nodes using the same framework</li> <li><strong>Validation</strong>: Fed-BioMed validates transform outputs automatically</li> </ul> </div> <h2 id=validation-and-type-safety>Validation and Type Safety</h2> <div class="admonition warning"> <p class=admonition-title>Automatic Validation</p> <p>Fed-BioMed automatically validates transform inputs/outputs. Focus on following framework requirements and avoiding common issues below.</p> </div> <p><strong>Key Considerations</strong></p> <ul> <li> <p>PyTorch Transforms:</p> <ul> <li>Input: <code>torch.Tensor</code> or <code>Dict[str, torch.Tensor]</code></li> <li>Output: Must return <code>torch.Tensor</code> or <code>Dict[str, torch.Tensor]</code> </li> </ul> </li> <li> <p>Scikit-learn Transforms:</p> <ul> <li>Input: <code>numpy.ndarray</code> or <code>Dict[str, numpy.ndarray]</code></li> <li>Output: Must return <strong>flattened</strong> <code>numpy.ndarray</code> only</li> <li>Use <code>.flatten()</code> or <code>.reshape(-1)</code> for sklearn compatibility</li> </ul> </li> </ul> <h2 id=best-practices>Best Practices</h2> <ul> <li><strong>Type consistency</strong>: Always return the expected framework type (tensor for PyTorch, array for sklearn)</li> <li><strong>Shape awareness</strong>: For sklearn, always flatten final output</li> <li><strong>Dtype preservation</strong>: Maintain appropriate data types (specific numeric types are expected by some models)</li> <li><strong>Error resilience</strong>: Design transforms to handle edge cases gracefully without crashing training</li> </ul> </article> </main> </div> <div class=right-col> <div id=right-sidebar class=sidebar-right> <nav class=toc> <!-- Render item list --> <label class=toc-title for=__toc> <span class=toc-icon></span> </label> <ul class=toc-list data-md-component=toc data-md-scrollfix> <!-- Table of contents item --> <li class=toc-item> <a href=#introduction class=md-nav__link> Introduction </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#transform-pipeline-overview class=md-nav__link> Transform Pipeline Overview </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#data-types-and-transform-requirements class=md-nav__link> Data Types and Transform Requirements </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#common-transform-operations class=md-nav__link> Common Transform Operations </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#writing-transform-functions class=md-nav__link> Writing Transform Functions </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#using-transforms-in-training-plans class=md-nav__link> Using Transforms in Training Plans </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#validation-and-type-safety class=md-nav__link> Validation and Type Safety </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#best-practices class=md-nav__link> Best Practices </a> </li> </ul> </nav> </div> </div> </div> </div> <!-- News Main Page--> </div> <footer> <div class=container-fluid> <div class=footer-first-inner> <div class=container> <div class=row> <div class=col-md-6> <div class=footer-contact> <strong>Address:</strong> <p>2004 Rte des Lucioles, 06902 Sophia Antipolis</p> <strong>E-mail:</strong> <p>fedbiomed _at_ inria _dot_ fr</p> </div> </div> <div class=col-md-6> <div class=footer-contact> <p>Fed-BioMed Â© 2022</p> </div> </div> </div> </div> </div> </div> </footer> <!-- JQuery --> <script src=https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js></script> <!-- Latest compiled and minified JavaScript --> <script src=https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js integrity=sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd crossorigin=anonymous></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/tablesort/5.2.1/tablesort.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../../assets/javascript/lunr.js></script> <script src=../../../assets/javascript/theme.js></script> <!-- GitHub buttons --> <script async defer src=https://buttons.github.io/buttons.js></script> </body> </html>