<!DOCTYPE html><html> <head><meta charset=UTF-8><meta name=viewport content="width=device-width, initial-scale=1"><meta name=robots context="index, archive"><!--  --><script>
      const versions_json = "../../../versions.json";
      const search_worker_js = "../../assets/javascript/search-worker.js";
      const search_index_json = "../../search/search_index.json";
      const base_url = '../..';
    </script><!-- Site title --><title>Advanced optimization in Fed-BioMed with dclearn - Fed-BioMed</title><link rel=icon type=image/x-icon href=../../favicon.ico><!-- Page description --><meta name=description content="Fed-BioMed can interface with declearn to propose powerful and advanced Optimizers"><!-- Page keywords --><meta name=keywords content=optimization,optimizer,declearn,OptiModule,Regularizer,regularization><!-- Page author --><!-- Latest compiled and minified CSS --><link rel=stylesheet href=https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css integrity=sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu crossorigin=anonymous><!-- Bootstrap Icons --><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css><link href=../../assets/_mkdocstrings.css rel=stylesheet><link href=../../assets/css/style.css rel=stylesheet></head> <body> <header> <div class="container-fluid top-bar"> <div class=brand> <a href=/ > <img src=../../assets/img/fedbiomed-logo-small.png> </a> </div> <nav class=top> <ul> <li class> <a href=../..>Home</a> </li> <li class> <a href=../../getting-started/what-is-fedbiomed/ >User Documentation</a> </li> <li class> <a href=../../pages/about-us/ >About</a> </li> <li id=clicker class=has-sub> More <i class="bi bi-chevron-down"></i> <ul class=sub-nav-menu> <li class> <a href=../../#funding>Funding</a> </li> <li class> <a href=../../news/ >News</a> </li> <li class> <a href=../../#contributors>Contributors</a> </li> <li class> <a href=../../#users>Users</a> </li> <li class> <a href=../../pages/roadmap/ >Roadmap</a> </li> <li class> <a href=../../#contact-us>Contact Us</a> </li> </ul> </li> </ul> </nav> </div> <div class="container-fluid top-bar-mobile"> <div class=mobile-bar> <div class=brand> <a href=../../ > <img src=../../assets/img/fedbiomed-logo-small.png> </a> </div> <div class=hum-menu> <img class=open src=../../assets/img/menu.svg> <img class=close style=display:none src=../../assets/img/cancel.svg> </div> </div> <nav class=top-mobile> <ul> <li class> <a href=../..>Home</a> </li> <li class> <a href=../../getting-started/what-is-fedbiomed/ >User Documentation</a> </li> <li class> <a href=../../pages/about-us/ >About</a> </li> <li id=clicker class=has-sub> More <i class="bi bi-chevron-down"></i> <ul class=sub-nav-menu> <li class> <a href=../../#funding>Funding</a> </li> <li class> <a href=../../news/ >News</a> </li> <li class> <a href=../../#contributors>Contributors</a> </li> <li class> <a href=../../#users>Users</a> </li> <li class> <a href=../../pages/roadmap/ >Roadmap</a> </li> <li class> <a href=../../#contact-us>Contact Us</a> </li> </ul> </li> </ul> </nav> </div> </header> <div class=main> <!-- Home page --> <div class=container-fluid> <div class=doc-row> <div class=left-col> <div class=sidebar-doc> <nav class=sidebar-inner> <ul class="sidebar-menu-left sub"> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Getting Started <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../getting-started/what-is-fedbiomed/ class>What's Fed-BioMed</a> </li> <li class> <a href=../../getting-started/getting-started/ class>Basic Example</a> </li> <li class> <a href=../../getting-started/fedbiomed-architecture/ class>Fedbiomed Architecture</a> </li> <li class> <a href=../../getting-started/fedbiomed-workflow/ class>Fedbiomed Workflow</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Tutorials <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Installation <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../tutorials/installation/0-basic-software-installation/ class>Software Installation</a> </li> <li class> <a href=../../tutorials/installation/1-setting-up-environment/ class>Setting Up Environment</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> PyTorch <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../tutorials/pytorch/01_PyTorch_MNIST_Single_Node_Tutorial/ class>PyTorch MNIST Basic Example</a> </li> <li class> <a href=../../tutorials/pytorch/02_Create_Your_Custom_Training_Plan/ class>How to Create Your Custom PyTorch Training Plan</a> </li> <li class> <a href=../../tutorials/pytorch/03_PyTorch_MNIST_local_vs_Federated/ class>MNIST classification with PyTorch, comparing federated model vs model trained locally</a> </li> <li class> <a href=../../tutorials/pytorch/04_PyTorch_Used_Cars_Dataset_Example/ class>PyTorch Used Cars Dataset Example</a> </li> <li class> <a href=../../tutorials/pytorch/05-Aggregation_in_Fed-BioMed/ class>PyTorch aggregation methods in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> MONAI <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../tutorials/monai/01_monai-2d-image-classification/ class>Federated 2d image classification with MONAI</a> </li> <li class> <a href=../../tutorials/monai/02_monai-2d-image-registration/ class>Federated 2d XRay registration with MONAI</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Scikit-Learn <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../tutorials/scikit-learn/01_sklearn_MNIST_classification_tutorial/ class>MNIST classification with Scikit-Learn Classifier (Perceptron)</a> </li> <li class> <a href=../../tutorials/scikit-learn/02_sklearn_sgd_regressor_tutorial/ class>Fed-BioMed to train a federated SGD regressor model</a> </li> <li class> <a href=../../tutorials/scikit-learn/03-other-scikit-learn-models/ class>Implementing other Scikit Learn models for Federated Learning</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Optimizers <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../tutorials/optimizers/01-fedopt-and-scaffold/ class>Advanced optimizers in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> FLamby <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../tutorials/flamby/flamby/ class>General Concepts</a> </li> <li class> <a href=../../tutorials/flamby/flamby-integration-into-fedbiomed/ class>FLamby integration in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Advanced <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../tutorials/advanced/in-depth-experiment-configuration/ class>In Depth Experiment Configuration</a> </li> <li class> <a href=../../tutorials/advanced/training-with-gpu/ class>PyTorch model training using a GPU</a> </li> <li class> <a href=../../tutorials/advanced/breakpoints/ class>Breakpoints</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Security <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../tutorials/security/differential-privacy-with-opacus-on-fedbiomed/ class>Using Differential Privacy with OPACUS on Fed-BioMed</a> </li> <li class> <a href=../../tutorials/security/non-private-local-central-dp-monai-2d-image-registration/ class>Local and Central DP with Fed-BioMed: MONAI 2d image registration</a> </li> <li class> <a href=../../tutorials/security/training-with-approved-training-plans/ class>Training Process with Training Plan Management</a> </li> <li class> <a href=../../tutorials/security/secure-aggregation/ class>Training with Secure Aggregation</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Biomedical data <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../tutorials/medical/medical-image-segmentation-unet-library/ class>Brain Segmentation</a> </li> </ul> </li> </ul> </li> <li data-adress=sub-1 class="current has-sub-side"> <div href class="parent-list current "> User Guide <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub active "> <li class> <a href=../glossary/ class>Glossary</a> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Deployment <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../deployment/deployment/ class>Introduction</a> </li> <li class> <a href=../deployment/deployment-vpn/ class>VPN Deployment</a> </li> <li class> <a href=../deployment/matrix/ class>Network matrix</a> </li> <li class> <a href=../deployment/security-model/ class>Security model</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Node <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../nodes/configuring-nodes/ class>Configuring Nodes</a> </li> <li class> <a href=../nodes/deploying-datasets/ class>Deploying Datasets</a> </li> <li class> <a href=../nodes/training-plan-security-manager/ class>Training Plan Management</a> </li> <li class> <a href=../nodes/using-gpu/ class>Using GPU</a> </li> <li class> <a href=../nodes/node-gui/ class>Node GUI</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Researcher <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../researcher/training-plan/ class>Training Plan</a> </li> <li class> <a href=../researcher/training-data/ class>Training Data</a> </li> <li class> <a href=../researcher/experiment/ class>Experiment</a> </li> <li class> <a href=../researcher/aggregation/ class>Aggregation</a> </li> <li class> <a href=../researcher/listing-datasets-and-selecting-nodes/ class>Listing Datasets and Selecting Nodes</a> </li> <li class> <a href=../researcher/model-testing-during-federated-training/ class>Model Validation on the Node Side</a> </li> <li class> <a href=../researcher/tensorboard/ class>Tensorboard</a> </li> </ul> </li> <li class=current> <a href=./ class="link current">Optimization</a> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Secure Aggregation <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../secagg/introduction/ class>Introduction</a> </li> <li class> <a href=../secagg/configuration/ class>Configuration</a> </li> <li class> <a href=../secagg/certificate-registration/ class>Certificate Registration</a> </li> <li class> <a href=../secagg/researcher-interface/ class>Managing Secure Aggregation in Researcher</a> </li> </ul> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Developer <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> API Reference <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Common <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../developer/api/common/constants/ class>Constants</a> </li> <li class> <a href=../../developer/api/common/data/ class>Data</a> </li> <li class> <a href=../../developer/api/common/environ/ class>Environ</a> </li> <li class> <a href=../../developer/api/common/exceptions/ class>Exceptions</a> </li> <li class> <a href=../../developer/api/common/json/ class>Json</a> </li> <li class> <a href=../../developer/api/common/logger/ class>Logger</a> </li> <li class> <a href=../../developer/api/common/message/ class>Message</a> </li> <li class> <a href=../../developer/api/common/messaging/ class>Messaging</a> </li> <li class> <a href=../../developer/api/common/models/ class>Model</a> </li> <li class> <a href=../../developer/api/common/optimizers/ class>Optimizers</a> </li> <li class> <a href=../../developer/api/common/repository/ class>Repository</a> </li> <li class> <a href=../../developer/api/common/tasks_queue/ class>TasksQueue</a> </li> <li class> <a href=../../developer/api/common/training_plans/ class>TrainingPlans</a> </li> <li class> <a href=../../developer/api/common/training_args/ class>TrainingArgs</a> </li> <li class> <a href=../../developer/api/common/utils/ class>Utils</a> </li> <li class> <a href=../../developer/api/common/validator/ class>Validator</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Node <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../developer/api/node/cli/ class>CLI</a> </li> <li class> <a href=../../developer/api/node/dataset_manager/ class>DatasetManager</a> </li> <li class> <a href=../../developer/api/node/node/ class>Node</a> </li> <li class> <a href=../../developer/api/node/node_state_manager/ class>NodeStateManager</a> </li> <li class> <a href=../../developer/api/node/training_plan_security_manager/ class>TrainingPlanSecurityManager</a> </li> <li class> <a href=../../developer/api/node/history_monitor/ class>HistoryMonitor</a> </li> <li class> <a href=../../developer/api/node/round/ class>Round</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Researcher <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../developer/api/researcher/aggregators/ class>Aggregators</a> </li> <li class> <a href=../../developer/api/researcher/datasets/ class>Datasets</a> </li> <li class> <a href=../../developer/api/researcher/experiment/ class>Experiment</a> </li> <li class> <a href=../../developer/api/researcher/filetools/ class>Filetools</a> </li> <li class> <a href=../../developer/api/researcher/job/ class>Job</a> </li> <li class> <a href=../../developer/api/researcher/monitor/ class>Monitor</a> </li> <li class> <a href=../../developer/api/researcher/node_state_agent/ class>NodeStateAgent</a> </li> <li class> <a href=../../developer/api/researcher/responses/ class>Responses</a> </li> <li class> <a href=../../developer/api/researcher/requests/ class>Requests</a> </li> <li class> <a href=../../developer/api/researcher/strategies/ class>Strategies</a> </li> <li class> <a href=../../developer/api/researcher/secagg/ class>Secagg</a> </li> </ul> </li> </ul> </li> <li class> <a href=../../developer/usage_and_tools/ class>Usage and Tools</a> </li> <li class> <a href=../../developer/ci/ class>Continuous Integration</a> </li> <li class> <a href=../../developer/definition-of-done/ class>Definition of Done</a> </li> <li class> <a href=../../developer/testing-in-fedbiomed/ class>Testing in Fed-BioMed</a> </li> </ul> </li> </ul> </nav> </div> </div> <div class=main-col> <main class=main-docs> <article> <h1 id=advanced-optimization-in-fed-biomed>Advanced Optimization in Fed-BioMed</h1> <p>Advanced Optimization can be done in <code>Fed-BioMed</code> through the use of <code>declearn</code>, a Python package that provides gradient-based <code>Optimizers</code>. <code>declearn</code> is cross-machine learning framework, meaning that it can be used with most machine learning frameworks (scikit-learn, PyTorch, Tensorflow, JAX, ...).</p> <p>The following chapter explores in depth how to use <code>declearn</code> optimization feature in <code>Fed-BioMed</code>. For an example, please refer to the <a href=../../tutorials/optimizers/01-fedopt-and-scaffold>Advanced Optimizer tutorial</a>.</p> <h2 id=1-introduction-to-declearn-based-optimizer-a-cross-framework-optimizer-library>1. Introduction to <code>Declearn</code> based Optimizer: a cross framework <code>Optimizer</code> library</h2> <h3 id=11-what-is-declearn-package>1.1. What is <code>declearn</code> package?</h3> <p><a href=https://gitlab.inria.fr/magnet/declearn/declearn2><code>declearn</code> package</a> is another Federated Learning framework modular and combinable, providing state-of-the-art gradient-based <code>Optimizer</code> algorithms. In <code>Fed-BioMed</code>, we are only using <a href=https://gitlab.inria.fr/magnet/declearn/declearn2/-/blob/optimizer-guide/docs/user-guide/optimizer.md>its <code>Optimization</code> facility</a>, leaving aside all other components of <code>declearn</code> that we don't use in <code>Fed-BioMed</code>.</p> <p><strong>References</strong>: For further details about <code>declearn</code>, you may visit:</p> <ul> <li> <p><a href=https://gitlab.inria.fr/magnet/declearn/declearn2><code>declearn</code> repository</a></p> </li> <li> <p><a href=https://magnet.gitlabpages.inria.fr/declearn/docs/2.2/ ><code>declearn</code> general documentation</a></p> </li> <li> <p><a href=https://gitlab.inria.fr/magnet/declearn/declearn2/-/blob/optimizer-guide/docs/user-guide/optimizer.md><code>declearn</code> Optimizers documentation</a></p> </li> </ul> <h3 id=12-declearn-interface-in-fed-biomed-the-optimizer-object>1.2. <code>declearn</code> interface in <code>Fed-BioMed</code>: the <code>Optimizer</code> object</h3> <p>In <code>Fed-BioMed</code>, we provide a <code>Optimizer</code> object, that works as an interface with <code>declearn</code>, and was made in order to use <code>declearn</code>'s Optimizers (see below <a href=#declearn-optimodules><code>declearn</code>'s <code>OptiModules</code></a> and <a href=#declearn-regularizers><code>declearn</code>'s <code>Regularizers</code></a>).</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers</span> <span class=kn>import</span> <span class=n>Optimizer</span>

<span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=mf>.1</span><span class=p>,</span> <span class=n>decay</span><span class=o>=</span><span class=mf>.0</span><span class=p>,</span> <span class=n>modules</span><span class=o>=</span><span class=p>[],</span> <span class=n>regualrizers</span><span class=o>=</span><span class=p>[])</span>
</code></pre></div> <p>with the following arguments:</p> <ul> <li> <p><code>lr</code>: the learning rate;</p> </li> <li> <p><code>decay</code>: the weight decay;</p> </li> <li> <p><code>modules</code>: a list of <code>declearn</code> 's <code>OptiModules</code> (or a list of <code>OptiModules' names</code>);</p> </li> <li> <p><code>regularizers</code>: a list of <code>declearn</code> 's <code>Regularizers</code> (or a list of <code>Regularizers' names</code>).</p> </li> </ul> <p><a name=declearn-optimodules></a></p> <h3 id=13-declearns-optimodules>1.3. <code>declearn</code>'s <code>OptiModules</code></h3> <p><code>declearn</code> <code>OptiModules</code> are modules that convey <code>Optimizers</code>, which purpose is to optimize a loss function (that can be written using a PyTorch loss function or defined in a scikit learn model) in order to optimize a model. Compatible <code>declearn</code> <code>OptiModules</code> with Fed-BioMed framework are defined in <code>fedbiomed.common.optimizers.declearn</code> module. They should be imported from <code>fedbiomed.common.optimizers.declearn</code>, as shown in the examples below. You can also import them direclty from <code>declearn</code>'s <code>declearn.optimizer.modules</code>, but they will be no guarentees it is compatible with Fed-BioMed. In fact, recommended method is importing modules through <code>fedbiomed.common.optimizers.declearn</code>.</p> <p><strong>Usage</strong>:</p> <ul> <li> <p>For basic SGD (Stochastic Gradient Descent), we don't need to specify a <code>declearn</code> <code>OptiModule</code> and/or a <code>Regularizer</code></p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.optimizer</span> <span class=kn>import</span> <span class=n>Optimizer</span>

<span class=n>lr</span> <span class=o>=</span> <span class=mf>.01</span>
<span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>)</span>
</code></pre></div> </li> <li> <p>For a specfic Optimizer like Adam, we need to import <code>AdamModule</code> from <code>declearn</code>. Hence, it yields:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.optimizer</span> <span class=kn>import</span> <span class=n>Optimizer</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span> <span class=kn>import</span> <span class=n>AdamModule</span>

<span class=n>lr</span> <span class=o>=</span> <span class=mf>.01</span>
<span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span> <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=n>AdamModule</span><span class=p>()])</span>
</code></pre></div> </li> <li> <p>It is possible to chain <code>Optimizer</code> with several <code>OptiModules</code>, meaning to use several <code>Optimizers</code>. Some chains of <code>OptiModule</code> may be non-sensical, so use it at your own risk! Below we showcase the use of Adam with Momentum</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.optimizer</span> <span class=kn>import</span> <span class=n>Optimizer</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span> <span class=kn>import</span> <span class=n>AdamModule</span><span class=p>,</span> <span class=n>MomentumModule</span>

<span class=n>lr</span> <span class=o>=</span> <span class=mf>.01</span>
<span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span> <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=n>AdamModule</span><span class=p>(),</span> <span class=n>MomentumModule</span><span class=p>()])</span>
</code></pre></div> </li> <li> <p>To get all comptible <code>OptiModule</code> in Fed-BioMed, one can run the [<code>list_optim_modules</code>][fedbiomed.common.optimizers.declearn.list_optim_modules].</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span> <span class=kn>import</span> <span class=n>list_optim_modules</span>

<span class=n>list_optim_modules</span><span class=p>()</span>
</code></pre></div> </li> </ul> <p>For further information on <code>declearn OptiModule</code>, please visit <a href=https://magnet.gitlabpages.inria.fr/declearn/docs/2.2/api-reference/optimizer/Optimizer/ ><code>declearn OptiModule</code></a> and <a href=https://gitlab.inria.fr/magnet/declearn/declearn2/-/blob/optimizer-guide/docs/user-guide/optimizer.md><code>declearn</code>'s Optimizers documentation</a>.</p> <p><strong>List of available Optimizers provided by <code>declearn</code></strong></p> <p>To get a list of all available Optimizers in declearn, please enter (after having loaded <code>Fed-BioMed</code> conda environment)</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>declearn.optimizer</span> <span class=kn>import</span> <span class=n>list_optim_modules</span>

<span class=n>list_optim_modules</span><span class=p>()</span>
</code></pre></div> <p><a name=declearn-regularizers></a></p> <h3 id=14-declearns-regularizers>1.4. <code>declearn</code>'s <code>Regularizers</code></h3> <p><code>declearn</code>'s <code>Regularizers</code> are objects that enable the use of <code>Regularizer</code>, which add an additional term to the loss function one wants to Optimize through the use of optimizer. It mainly helps to get a more generalizable model, and prevents overfitting.</p> <p>The optimization equation yields to:</p> <div class=arithmatex>\[ \theta_{t+1} := \theta_t - \eta \vec{\nabla} f_{x,y} + \alpha \lVert \theta_t \rVert \]</div> <p>with</p> <p><span class=arithmatex>\(\theta_t : \textrm{model weights at update } t\)</span></p> <p><span class=arithmatex>\(\eta : \textrm{learning rate}\)</span></p> <p><span class=arithmatex>\(\alpha : \textrm{regularization coefficient}\)</span></p> <p><span class=arithmatex>\(f_{x,y}: \textrm{Loss function used for optimizing the model}\)</span></p> <p><code>Regularizers</code> should be used and combined with an Optimizer. For instance, SGD with Ridge regression, or Adam with Lasso regression. <a href=https://arxiv.org/abs/1812.06127><code>FedProx</code></a> is also considered as a regularization.</p> <div class="admonition note"> <p class=admonition-title>Optimizer without OptiModules</p> <p>When no <code>OptiModules</code> are specified in the <code>modules</code> argument of <code>Optimizer</code>, plain SGD algorithm is set by default for the optimization.</p> </div> <p><strong>Usage</strong>:</p> <ul> <li> <p>for example, <strong>SGD with Ridge regression</strong> will be written as:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.optimizer</span> <span class=kn>import</span> <span class=n>Optimizer</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span> <span class=kn>import</span> <span class=n>RidgeRegularizer</span>

<span class=n>lr</span> <span class=o>=</span> <span class=mf>.01</span>
<span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span> <span class=n>regularizers</span><span class=o>=</span><span class=p>[</span><span class=n>RidgeRegularizer</span><span class=p>()])</span>
</code></pre></div> </li> <li> <p><strong><a href=https://arxiv.org/abs/1412.6980>Adam</a> with Lasso Regression</strong>:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.optimizer</span> <span class=kn>import</span> <span class=n>Optimizer</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span> <span class=kn>import</span> <span class=n>AdamModule</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span> <span class=kn>import</span> <span class=n>LassoRegularizer</span>

<span class=n>lr</span> <span class=o>=</span> <span class=mf>.01</span>
<span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span> <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=n>AdamModule</span><span class=p>()],</span> <span class=n>regularizers</span><span class=o>=</span><span class=p>[</span><span class=n>LassoRegularizer</span><span class=p>()])</span>
</code></pre></div> </li> <li> <p>Chaining several Regularizers: an example with Ridge and Lasso regularizers, and <a href=https://arxiv.org/abs/1412.6980>Adam</a> with momentum as the Optimizer.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.optimizer</span> <span class=kn>import</span> <span class=n>Optimizer</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span> <span class=kn>import</span> <span class=n>LassoRegularizer</span><span class=p>,</span> <span class=n>RidgeRegularizer</span>

<span class=n>lr</span> <span class=o>=</span> <span class=mf>.01</span>
<span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span> <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=n>AdamModule</span><span class=p>(),</span> <span class=n>MomentumModule</span><span class=p>()],</span> <span class=n>regularizers</span><span class=o>=</span><span class=p>[</span><span class=n>LassoRegularizer</span><span class=p>(),</span> <span class=n>RidgeRegularizer</span><span class=p>()])</span>
</code></pre></div> </li> </ul> <p>For further information on <code>declearn Regularizer</code>, please visit <a href=https://magnet.gitlabpages.inria.fr/declearn/docs/2.2/api-reference/optimizer/regularizers/Regularizer/ ><code>declearn Regularizers</code> documentation webpage</a> </p> <h3 id=15-chaining-optimizers-and-regularizers-with-declearn-modules>1.5. Chaining <code>Optimizers</code> and <code>Regularizers</code> with <code>declearn</code> modules</h3> <p>It is possible in <code>declearn</code> to chain several <code>OptiModules</code> and <code>Regularizers</code> in an Optimizer. Generaly speaking, <code>Optimizer</code> in <code>declearn</code> can be written as:</p> <div class=arithmatex>\[ \begin{equation} \theta_{t+1} := \theta_t - \eta\ \underbrace{ Opt( \vec{\nabla} f_{x,y} - \overbrace{ Reg(\theta_t)}^\textrm{Regularizer})}_\textrm{OptiModule} - \tau \theta_t \end{equation} \]</div> <p>with</p> <p><span class=arithmatex>\(Opt : \textrm{an OptiModule}\)</span></p> <p><span class=arithmatex>\(Reg : \textrm{a Regularizer}\)</span></p> <p><span class=arithmatex>\(\theta : \textrm{model weight}\)</span></p> <p><span class=arithmatex>\(\eta : \textrm{learning rate}\)</span></p> <p><span class=arithmatex>\(\tau : \textrm{weight decay}\)</span></p> <p><span class=arithmatex>\(f_{x,y}: \textrm{Loss function used for optimizing the model}\)</span></p> <p>The above holds for a single <code>Regularizer</code> and <code>OptiModule</code>. When using (ie <em>chaining</em>) several <code>OptiModules</code> and <code>Regularizers</code> in an <code>Optimizer</code>, the above optimization equation becomes:</p> <div class=arithmatex>\[\theta_{t+1} := \theta_t - \eta\ \underbrace{ Opt_{i=1} \circ Opt_{i=2} \,\circ... \circ \, Opt_{i=n}( \vec{\nabla} f_{x,y} - \overbrace{ Reg_{i=1}\circ Reg_{i=2}\circ... \circ \,Reg_{i=m}(\theta_t)}^\textrm{ Regularizers})}_\textrm{OptiModules} - \tau \theta_t \]</div> <p>where</p> <p><span class=arithmatex>\(Opt_{1\le i \le n}: \textrm{ OptiModules, with } n \textrm{ the total number of OptiModules used}\)</span></p> <p><span class=arithmatex>\(Reg_{1\le i \le m}: \textrm{ Regularizers, with } m \textrm{ the total number of Regularizers used}\)</span></p> <p><strong>Example</strong>: let's write an <code>Optimizer</code> using <code>RMSProp</code> and <code>Momentum</code> <code>OptiModules</code>, and both Lasso and Ridge Regularizers.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.optimizer</span> <span class=kn>import</span> <span class=n>Optimizer</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span>  <span class=kn>import</span> <span class=n>RMSPropModule</span><span class=p>,</span> <span class=n>MomentumModule</span><span class=p>,</span> <span class=n>LassoRegularizer</span><span class=p>,</span> <span class=n>RidgeRegularizer</span>

<span class=n>lr</span> <span class=o>=</span> <span class=mf>.01</span>
<span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span>
          <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=n>RMSPropModule</span><span class=p>(),</span> <span class=n>MomentumModule</span><span class=p>()],</span>
          <span class=n>regularizers</span><span class=o>=</span><span class=p>[</span><span class=n>LassoRegularizer</span><span class=p>(),</span> <span class=n>RidgeRegularizer</span><span class=p>()])</span>
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Using list of strings instead of list of modules</p> <p>In <code>declearn</code>, it is possible to use name of modules instead of loading the actual modules. In the script below, we are rewritting the same <code>Optimizer</code> as the one above but by specifying the module names. A convinient way to get the naming is to use <code>list_optim_modules</code> and <code>list_optim_regularizers</code> functions, that map module names with their classes respectively.</p> </div> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.optimizer</span> <span class=kn>import</span> <span class=n>Optimizer</span>


<span class=n>lr</span> <span class=o>=</span> <span class=mf>.01</span>
<span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span>
          <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;adam&#39;</span><span class=p>,</span> <span class=s1>&#39;momentum&#39;</span><span class=p>],</span>
          <span class=n>regularizers</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;lasso&#39;</span><span class=p>,</span> <span class=s1>&#39;ridge&#39;</span><span class=p>])</span>
</code></pre></div> <p>To get to know specifcities about all <code>declearn</code>'s modules, please visit <a href=https://magnet.gitlabpages.inria.fr/declearn/docs/2.2/ ><code>declearn</code> webpage</a>.</p> <h4 id=how-to-use-well-known-federated-learning-algorithms-with-declearn-in-fed-biomed>How to use well-known Federated-Learning algorithms with <code>declearn</code> in <code>Fed-BioMed</code>?</h4> <p>Please refer to <a href=#federated-learning-algorithms-table>the following section of this page.</a></p> <h2 id=2-declearn-optimizer-on-node-side>2. <code>declearn</code> optimizer on Node side</h2> <p>In order to use <code>declearn</code> to optimize <code>Node</code>s local model, you will have to edit <code>init_otpimizer</code> method in the <code>TrainingPlan</code>. Below we showcase how to use it with PyTorch framework (using Adam and Ridge regularizer for the optimization).</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>TorchTrainingPlan</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.optimizer</span> <span class=kn>import</span> <span class=n>Optimizer</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span>  <span class=kn>import</span> <span class=n>AdamModule</span><span class=p>,</span> <span class=n>RidgeRegularizer</span>
<span class=o>...</span>

<span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>TorchTrainingPlan</span><span class=p>):</span>
    <span class=o>...</span>

    <span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>deps</span> <span class=o>=</span> <span class=p>[</span>
                <span class=s2>&quot;from fedbiomed.common.optimizers.optimizer import Optimizer&quot;</span><span class=p>,</span>
                <span class=s2>&quot;from fedbiomed.common.optimizers.declearn  import AdamModule, RidgeRegularizer&quot;</span>
                <span class=p>]</span>

        <span class=k>return</span> <span class=n>deps</span>

    <span class=k>def</span> <span class=nf>init_optimizer</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=mf>.01</span><span class=p>,</span> <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=n>AdamModule</span><span class=p>()],</span> <span class=n>regularizers</span><span class=o>=</span><span class=p>[</span><span class=n>RidgeRegularizer</span><span class=p>()])</span>
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Important</p> <p>You should specify the <code>OptiModules</code> imported in both the imports at the begining of the <code>Training Plan</code> as well as in the dependencies (in the <code>init_dependencies</code> method within the <code>Training Plan</code>). The same holds for <code>declearn</code>'s <code>Regularizers</code>.</p> </div> <p>Syntax will be the same for scikit-learn as shown below, using the same <code>Optimizer</code>:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>FedSGDClassifier</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.optimizer</span> <span class=kn>import</span> <span class=n>Optimizer</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span> <span class=kn>import</span> <span class=n>AdamModule</span><span class=p>,</span> <span class=n>RidgeRegularizer</span>
<span class=o>...</span>

<span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>FedSGDClassifier</span><span class=p>):</span>
    <span class=o>...</span>

    <span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>deps</span> <span class=o>=</span> <span class=p>[</span>
                <span class=s2>&quot;from fedbiomed.common.optimizers.optimizer import Optimizer&quot;</span><span class=p>,</span>
                <span class=s2>&quot;from fedbiomed.common.optimizers.declearn  import AdamModule, RidgeRegularizer&quot;</span>
                <span class=p>]</span>

        <span class=k>return</span> <span class=n>deps</span>

    <span class=k>def</span> <span class=nf>init_optimizer</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=mf>.01</span><span class=p>,</span> <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=n>AdamModule</span><span class=p>()],</span> <span class=n>regularizers</span><span class=o>=</span><span class=p>[</span><span class=n>RidgeRegularizer</span><span class=p>()])</span>
</code></pre></div> <h2 id=3-declearn-optimizer-on-researcher-side-fedopt>3. <code>declearn</code> optimizer on Researcher side (<code>FedOpt</code>)</h2> <p><code>Fed-BioMed</code> provides a way to use <strong>Adaptive Federated Optimization</strong>, introduced as <a href=https://arxiv.org/pdf/2003.00295.pdf><code>FedOpt</code> in this paper</a>. In the paper, authors considered the difference of the global model weights between 2 successive <code>Rounds</code> as a <em>pseudo gradient</em>, paving the way to the possbility to have <code>Optimizers</code> on <code>Researcher</code> side, optimizing the updates of the global model. To do so, <code>fedbiomed.researcher.experiment.Experiment</code> has a method to set the <code>Researcher Optimizer</code>: <a href=../../developer/api/researcher/experiment/#fedbiomed.researcher.experiment.Experiment.set_agg_optimizer><code>Experiment.set_agg_optimizer</code></a></p> <p>Below an example using the <code>set_agg_optimizer</code> with <code>FedYogi</code>:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.researcher.experiment</span> <span class=kn>import</span> <span class=n>Experiment</span>
<span class=kn>from</span> <span class=nn>fedbiomed.researcher.aggregators</span> <span class=kn>import</span> <span class=n>FedAverage</span>
<span class=kn>from</span> <span class=nn>fedbiomed.researcher.strategies.default_strategy</span> <span class=kn>import</span> <span class=n>DefaultStrategy</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span>  <span class=kn>import</span> <span class=n>YogiModule</span> <span class=k>as</span> <span class=n>FedYogi</span>

<span class=n>tags</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;#my-data&#39;</span><span class=p>]</span>

<span class=n>exp</span> <span class=o>=</span> <span class=n>Experiment</span><span class=p>()</span>
<span class=n>exp</span><span class=o>.</span><span class=n>set_training_plan_class</span><span class=p>(</span><span class=n>training_plan_class</span><span class=o>=</span><span class=n>MyTrainingPlan</span><span class=p>)</span>
<span class=n>exp</span><span class=o>.</span><span class=n>set_tags</span><span class=p>(</span><span class=n>tags</span> <span class=o>=</span> <span class=n>tags</span><span class=p>)</span>
<span class=n>exp</span><span class=o>.</span><span class=n>set_aggregator</span><span class=p>(</span><span class=n>aggregator</span><span class=o>=</span><span class=n>FedAverage</span><span class=p>())</span>
<span class=n>exp</span><span class=o>.</span><span class=n>set_round_limit</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
<span class=n>exp</span><span class=o>.</span><span class=n>set_training_data</span><span class=p>(</span><span class=n>training_data</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>from_tags</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>exp</span><span class=o>.</span><span class=n>set_job</span><span class=p>()</span>
<span class=n>exp</span><span class=o>.</span><span class=n>set_strategy</span><span class=p>(</span><span class=n>node_selection_strategy</span><span class=o>=</span><span class=n>DefaultStrategy</span><span class=p>)</span>

<span class=c1># here we are adding an Optimizer on Researcher side (FedYogi)</span>
<span class=n>fed_opt</span> <span class=o>=</span> <span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=mf>.8</span><span class=p>,</span> <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=n>FedYogi</span><span class=p>()])</span>
<span class=n>exp</span><span class=o>.</span><span class=n>set_agg_optimizer</span><span class=p>(</span><span class=n>fed_opt</span><span class=p>)</span>

<span class=n>exp</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>increase</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div> <div class="admonition warning"> <p class=admonition-title>Important</p> <p><strong>You may have noticed that we are using <code>FedAverage</code> in the <code>Experiment</code> configuration, while using <code>YogiModule</code> as an <code>Optimizer</code>. In fact, <code>FedAverage</code> <code>Aggregator</code> in <code>Fed-BioMed</code> refers to the way model weights are aggregated before optimization, and should not be confused with the <a href=https://arxiv.org/abs/1602.05629>whole <code>FedAvg</code> algorithm</a>, which is basically a SGD optimizer performed on <code>Node</code> side using <code>FedAvg</code> <code>Aggregtor</code> on <code>Researcher</code> side.</strong></p> </div> <p>One can also pass directly the <code>agg_optimizer</code> in the <code>Experiment</code> object constructor:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.researcher.experiment</span> <span class=kn>import</span> <span class=n>Experiment</span>
<span class=kn>from</span> <span class=nn>fedbiomed.researcher.aggregators</span> <span class=kn>import</span> <span class=n>FedAverage</span>
<span class=kn>from</span> <span class=nn>fedbiomed.researcher.strategies.default_strategy</span> <span class=kn>import</span> <span class=n>DefaultStrategy</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span> <span class=kn>import</span> <span class=n>YogiModule</span> <span class=k>as</span> <span class=n>FedYogi</span>


<span class=n>tags</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;#my-data&#39;</span><span class=p>]</span>
<span class=n>fed_opt</span> <span class=o>=</span> <span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=mf>.8</span><span class=p>,</span> <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=n>FedYogi</span><span class=p>()])</span>


<span class=n>exp</span> <span class=o>=</span> <span class=n>Experiment</span><span class=p>(</span><span class=n>tags</span><span class=o>=</span><span class=n>tags</span><span class=p>,</span>
                 <span class=n>training_plan_class</span><span class=o>=</span><span class=n>MyTrainingPlan</span><span class=p>,</span>
                 <span class=n>round_limit</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
                 <span class=n>agg_optimizer</span><span class=o>=</span><span class=n>fed_opt</span><span class=p>,</span>
                 <span class=n>aggregator</span><span class=o>=</span><span class=n>FedAverage</span><span class=p>(),</span>
                 <span class=n>node_selection_strategy</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span>

<span class=n>exp</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>increase</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div> <h2 id=4-declearn-auxiliary-variables-based-optimizers>4. <code>declearn</code> auxiliary variables based <code>Optimizers</code></h2> <p>In this subsection, we will take a look at some specific <code>Optimizers</code> that are built around <code>auxiliary variables</code>.</p> <h3 id=41-what-is-an-auxiliary-variable>4.1. What is an auxiliary variable?</h3> <p><code>Auxiliary variable</code> is a parameter that is needed for an <code>Optimizer</code> that requieres to be exchanged between <code>Nodes</code> and <code>Researcher</code>, in addition to model parameters. <a href=https://arxiv.org/abs/1910.06378><code>Scaffold</code></a> is an example of such <code>Optimizer</code>, because built upon correction states, exchanged from <code>Nodes</code> and <code>Researcher</code>.</p> <p>These <code>Optimizers</code> may come with a specific <code>Researcher</code> version (for <code>Scaffold</code> it is <code>ScaffoldServerModule</code>) and a <code>Node</code> version (resp. <code>ScaffoldClientModule</code>). They may work in a synchronous fashion: <code>Researcher</code> optimizer version may expect auxiliary variables from <code>Node</code> optimizer, and the other way arround (<code>Node</code> optimizer expecting auxiliary variable input from <code>Reseracher</code> optimizer version).</p> <h3 id=42-an-example-using-optimizer-with-auxiliary-variables-scaffold-with-declearn>4.2. An example using <code>Optimizer</code> with auxiliary variables: <code>Scaffold</code> with <code>declearn</code></h3> <p>In the last sub-section, we introduced <a href=https://arxiv.org/abs/1910.06378><code>Scaffold</code></a>. Let's see now how to use it in <code>Fed-BioMed</code> framework.</p> <div class="admonition note"> <p class=admonition-title>About native Scaffold implementation in Fed-BioMed</p> <p><code>Fed-BioMed</code> provides its own implementation of <a href=https://fedbiomed.org/latest/developer/api/researcher/aggregators/#fedbiomed.researcher.aggregators.Scaffold><code>Scaffold</code> <code>Aggregator</code></a>, that is only for PyTorch framework. It only works with PyTorch native optimizers <code>torch.optim.Optimizer</code> for the <code>Node Optimizer</code>.</p> </div> <p><strong><code>Training Plan</code> design</strong></p> <p>In the current subsection, we showcase how to edit your <code>Training Plan</code> for PyTorch in order to use <code>Scaffold</code></p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>TorchTrainingPlan</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.optimizer</span> <span class=kn>import</span> <span class=n>Optimizer</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.optimizers.declearn</span> <span class=kn>import</span> <span class=n>ScaffoldClientModule</span>
<span class=o>...</span>

<span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>TorchTrainingPlan</span><span class=p>):</span>
    <span class=o>...</span>

    <span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>deps</span> <span class=o>=</span> <span class=p>[</span>
                <span class=s2>&quot;from fedbiomed.common.optimizers.optimizer import Optimizer&quot;</span><span class=p>,</span>
                <span class=s2>&quot;from fedbiomed.common.optimizers.declearn import ScaffoldClientModule&quot;</span><span class=p>,</span>
                <span class=p>]</span>

        <span class=k>return</span> <span class=n>deps</span>

    <span class=k>def</span> <span class=nf>init_optimizer</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=mf>.01</span><span class=p>,</span> <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=n>ScaffoldClientModule</span><span class=p>()])</span>
</code></pre></div> <p><strong><code>Experiment</code> design</strong></p> <p>This is how <code>Experiment</code> can be designed (on the <code>Researcher</code> side)</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.researcher.experiment</span> <span class=kn>import</span> <span class=n>Experiment</span>
<span class=kn>from</span> <span class=nn>fedbiomed.researcher.aggregators</span> <span class=kn>import</span> <span class=n>FedAverage</span>
<span class=kn>from</span> <span class=nn>fedbiomed.researcher.strategies.default_strategy</span> <span class=kn>import</span> <span class=n>DefaultStrategy</span>
<span class=kn>from</span> <span class=nn>declearn.optimizer.modules</span> <span class=kn>import</span> <span class=n>ScaffoldServerModule</span>


<span class=n>tags</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;#my-data&#39;</span><span class=p>]</span>
<span class=n>fed_opt</span> <span class=o>=</span> <span class=n>Optimizer</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=mf>.8</span><span class=p>,</span> <span class=n>modules</span><span class=o>=</span><span class=p>[</span><span class=n>ScaffoldServerModule</span><span class=p>()])</span>


<span class=n>exp</span> <span class=o>=</span> <span class=n>Experiment</span><span class=p>(</span><span class=n>tags</span><span class=o>=</span><span class=n>tags</span><span class=p>,</span>
                 <span class=n>training_plan_class</span><span class=o>=</span><span class=n>MyTrainingPlan</span><span class=p>,</span>
                 <span class=n>round_limit</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
                 <span class=n>agg_optimizer</span><span class=o>=</span><span class=n>fed_opt</span><span class=p>,</span>
                 <span class=n>aggregator</span><span class=o>=</span><span class=n>FedAverage</span><span class=p>(),</span>
                 <span class=n>node_selection_strategy</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span>

<span class=n>exp</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>increase</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div> <div class="admonition warning"> <p class=admonition-title>Important</p> <p><strong>You may have noticed that we are using <code>FedAverage</code> in the <code>Experiment</code> configuration, while using <code>ScaffoldServerModule</code> \ <code>ScaffoldClientModule</code> as an <code>Optimizer</code>. In fact, <code>FedAverage</code> <code>Aggregator</code> in <code>Fed-BioMed</code> refers to the way model weights are aggregated before optimization, and should not be confused with the <a href=https://arxiv.org/abs/1602.05629>whole <code>FedAvg</code> algorithm</a>, which is basically a SGD optimizer performed on <code>Node</code> side using <code>FedAvg</code> <code>Aggregtor</code>.</strong></p> </div> <div class="admonition warning"> <p class=admonition-title>Security issues using auxiliary variables when using SecAgg</p> <p>Currently, <code>declearn</code> optimizers based on auxiliary variables (like <code>Scaffold</code>), do not have their auxiliary variables protected by <a href=../../user-guide/secagg/introduction><code>SecAgg</code></a> secure aggregation mechanism yet. This is something that will be changed in future <code>Fed-BioMed</code> releases. </p> </div> <p>You can find more examples in <a href=../../tutorials/optimizers/01-fedopt-and-scaffold.ipynb>Advanced Optimizers tutorial</a></p> <h2 id=table-to-use-common-federated-learning-algorithm-with-declearn-in-fed-biomed>Table to use common Federated Learning algorithm with <code>declearn</code> in <code>Fed-BioMed</code></h2> <p><a name=federated-learning-algorithms-table></a></p> <p>Below we have gathered some of the most well known algorithms in Federated Learning in the following table (as a reminder, <code>Node Optimizer</code> must e defined in the <code>TrainingPlan</code>, whereas <code>Researcher Optimizer</code> in the <code>Experiment</code> object):</p> <table> <thead> <tr> <th>Federated Learning Algorithm</th> <th>Node Optimizer</th> <th>Researcher Optimizer</th> <th>Aggregator</th> </tr> </thead> <tbody> <tr> <td><a href=https://arxiv.org/pdf/1911.09030>AdaAlter (distributed AdaGrad)</a></td> <td>AdaGrad <code>Optimizer(lr=xx, modules=[AdaGradModule()])</code></td> <td>None</td> <td><code>FedAverage</code></td> </tr> <tr> <td><a href=https://arxiv.org/pdf/2003.00295>FedAdagrad</a></td> <td>SGD <code>Optimizer(lr=xx)</code></td> <td>AdaGrad <code>Optimizer(lr=xx, modules=[AdaGradModule()])</code></td> <td><code>FedAverage</code></td> </tr> <tr> <td><a href=https://arxiv.org/pdf/2003.00295>FedAdam</a></td> <td>SGD <code>Optimizer(lr=xx)</code></td> <td>Adam <code>Optimizer(lr=xx, modules=[AdamModule()])</code></td> <td><code>FedAverage</code></td> </tr> <tr> <td><a href=https://arxiv.org/abs/1602.05629>FedAvg</a></td> <td>SGD <code>Optimizer(lr=xx)</code></td> <td>None</td> <td><code>FedAverage</code></td> </tr> <tr> <td><a href=https://arxiv.org/abs/1812.06127>FedProx</a></td> <td>SGD <code>Optimizer(lr=xx, regularizers=[FedProxRegularizer])</code></td> <td>None</td> <td><code>FedAverage</code></td> </tr> <tr> <td><a href=https://arxiv.org/pdf/2003.00295>FedYogi</a></td> <td>SGD <code>Optimizer(lr=xx)</code></td> <td>Yogi <code>Optimizer(lr=xx, modules=[YogiModule()])</code></td> <td><code>FedAverage</code></td> </tr> <tr> <td><a href=https://arxiv.org/abs/1910.06378>Scaffold</a></td> <td>SGD <code>Optimizer(lr=xx, modules=[ScaffoldClientModule()])</code></td> <td>SGD <code>Optimizer(lr=xx, modules=[ScaffoldServerModule()])</code></td> <td><code>FedAverage</code></td> </tr> </tbody> </table> <h2 id=5-common-pitfalls-using-declearn-optimizers-in-fed-biomed>5. Common Pitfalls using <code>declearn</code> Optimizers in <code>Fed-BioMed</code></h2> <p>Below, we are summerizing common pitfalls that may occur when using <code>declearn</code> package in <code>Fed-BioMed</code>:</p> <ul> <li><code>Optimization</code> on <code>Researcher</code> side is only possible through <code>declearn</code> Optimizers (and not through native Optimizers such as PyTorch Optimizers);</li> <li>Some <code>Optimizers</code> may requiere some synchronization: it is the case of <code>Scaffold</code> related modules, ie <code>ScaffoldClientModule</code> and <code>ScaffoldServerModule</code>;</li> <li>For the moment <code>declearn</code> Optimizers that use <code>auxiliary variables</code> (such as <code>Scaffold</code>) cannot be protected yet with <a href=../../user-guide/secagg/introduction/ >Secure Aggregation</a>;</li> <li>For the moment, <code>declearn</code>'s <code>optimizer</code> only comes with a unique learning rate (multiple learning rates <code>Optimizers</code>, for example pytorch optimizers <code>torch.optim.Optimizer</code> can handle a learning rate per model layer );</li> <li>When chaining <code>declearn</code>'s <code>OptiModules</code>, it is only possible to use a unique learning rate, that will be the same for all <code>OptiModules</code>, and that won't change during a <code>Round</code>;</li> <li>check for inconcistent Optimizers! Using a <code>Regularizer</code> on <code>Researcher</code> side may be non-sensical, even if it is doable within <code>declearn</code>;</li> <li><a href=https://fedbiomed.org/latest/developer/api/researcher/aggregators/#fedbiomed.researcher.aggregators.Scaffold><code>Scaffold</code> <code>Fed-BioMed</code> aggregator</a> must not be used when using both <code>ScaffoldServerModule</code> and <code>ScaffoldClientModule</code>. This <code>aggregator</code> is in fact an alternative to the <code>declearn</code> <code>scaffold</code>, and you have to choose between the <code>Fed-BioMed</code> native version of <code>Scaffold</code> and the <code>declearn</code> 's one. Please note that <code>Fed-BioMed aggregator Scaffold</code> is deprecated, hence, the use of <code>ScaffoldServerModule</code> and <code>ScaffoldClientModule</code> is highly encouraged.</li> </ul> <h2 id=conclusion>Conclusion</h2> <p>We have seen how to use <code>declearn</code> <code>Optimizers</code> in <code>Fed-BioMed</code>. In <code>Fed-BioMed</code>, it is possible to set an <code>Optimizer</code> on both the <code>Node</code> and the <code>Researcher</code> side:</p> <ul> <li> <p>On <code>Node</code> side, such <code>Optimizer</code> is defined in <code>Training Plan</code> and is used to optimize <code>Nodes</code>' local models;</p> </li> <li> <p>On <code>Researcher</code> side, <code>Optimizer</code> is defined in the <code>Experiment</code>, and is made for optimizing global model.</p> </li> </ul> <p>When used with <code>declearn</code> package, <code>Fedd-BioMed</code> <code>Aggregator</code> is used for aggregating weights, before any potential optiization: <code>FedAverage</code> does the weighted sum of all local models sent back by the <code>Nodes</code>.</p> <p><code>declearn</code> comes with the possibility of <em>chaining</em> <code>Optimizers</code>, by passing a list of <code>OptiModule</code> and <code>Regularizers</code>, making possible to try out some more complex optimization process.</p> <p>Check <a href=../../tutorials/optimizers/01-fedopt-and-scaffold.ipynb>the tutorial related to the use of <code>declearn</code>'s <code>Optimizers</code></a></p> </article> </main> </div> <div class=right-col> <div id=right-sidebar class=sidebar-right> <nav class=toc> <!-- Render item list --> <label class=toc-title for=__toc> <span class=toc-icon></span> </label> <ul class=toc-list data-md-component=toc data-md-scrollfix> <!-- Table of contents item --> <li class=toc-item> <a href=#1-introduction-to-declearn-based-optimizer-a-cross-framework-optimizer-library class=md-nav__link> 1. Introduction to Declearn based Optimizer: a cross framework Optimizer library </a> <nav class=toc-nav aria-label="1. Introduction to Declearn based Optimizer: a cross framework Optimizer library"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#11-what-is-declearn-package class=md-nav__link> 1.1. What is declearn package? </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#12-declearn-interface-in-fed-biomed-the-optimizer-object class=md-nav__link> 1.2. declearn interface in Fed-BioMed: the Optimizer object </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#13-declearns-optimodules class=md-nav__link> 1.3. declearn's OptiModules </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#14-declearns-regularizers class=md-nav__link> 1.4. declearn's Regularizers </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#15-chaining-optimizers-and-regularizers-with-declearn-modules class=md-nav__link> 1.5. Chaining Optimizers and Regularizers with declearn modules </a> <nav class=toc-nav aria-label="1.5. Chaining Optimizers and Regularizers with declearn modules"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#how-to-use-well-known-federated-learning-algorithms-with-declearn-in-fed-biomed class=md-nav__link> How to use well-known Federated-Learning algorithms with declearn in Fed-BioMed? </a> </li> </ul> </nav> </li> </ul> </nav> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#2-declearn-optimizer-on-node-side class=md-nav__link> 2. declearn optimizer on Node side </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#3-declearn-optimizer-on-researcher-side-fedopt class=md-nav__link> 3. declearn optimizer on Researcher side (FedOpt) </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#4-declearn-auxiliary-variables-based-optimizers class=md-nav__link> 4. declearn auxiliary variables based Optimizers </a> <nav class=toc-nav aria-label="4. declearn auxiliary variables based Optimizers"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#41-what-is-an-auxiliary-variable class=md-nav__link> 4.1. What is an auxiliary variable? </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#42-an-example-using-optimizer-with-auxiliary-variables-scaffold-with-declearn class=md-nav__link> 4.2. An example using Optimizer with auxiliary variables: Scaffold with declearn </a> </li> </ul> </nav> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#table-to-use-common-federated-learning-algorithm-with-declearn-in-fed-biomed class=md-nav__link> Table to use common Federated Learning algorithm with declearn in Fed-BioMed </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#5-common-pitfalls-using-declearn-optimizers-in-fed-biomed class=md-nav__link> 5. Common Pitfalls using declearn Optimizers in Fed-BioMed </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#conclusion class=md-nav__link> Conclusion </a> </li> </ul> </nav> </div> </div> </div> </div> <!-- News Main Page--> </div> <footer> <div class=container-fluid> <div class=footer-first-inner> <div class=container> <div class=row> <div class=col-md-6> <div class=footer-contact> <strong>Address:</strong> <p>2004 Rte des Lucioles, 06902 Sophia Antipolis</p> <strong>E-mail:</strong> <p>fedbiomed _at_ inria _dot_ fr</p> </div> </div> <div class=col-md-6> <div class=footer-contact> <p>Fed-BioMed © 2022</p> </div> </div> </div> </div> </div> </div> </footer> <!-- JQuery --> <script src=https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js></script> <!-- Latest compiled and minified JavaScript --> <script src=https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js integrity=sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd crossorigin=anonymous></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/tablesort/5.2.1/tablesort.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../assets/javascript/lunr.js></script> <script src=../../assets/javascript/theme.js></script> </body> </html>