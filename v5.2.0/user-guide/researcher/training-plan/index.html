<!DOCTYPE html><html> <head><meta charset=UTF-8><meta name=viewport content="width=device-width, initial-scale=1"><meta name=robots context="index, archive"><!--  --><script>
      const versions_json = "../../../../versions.json";
      const search_worker_js = "../../../assets/javascript/search-worker.js";
      const search_index_json = "../../../search/search_index.json";
      const base_url = '../../..';
    </script><!-- Site title --><title>The Training Plan of Fed-BioMed - Fed-BioMed</title><link rel=icon type=image/x-icon href=../../../favicon.ico><!-- Page description --><meta name=description content="A training plan is a class that defines the federated model training. It is responsible for providing base methods which allow every node to perform the training process."><!-- Page keywords --><meta name=keywords content="training data,training plan,fedbiomed"><!-- Page author --><!-- Latest compiled and minified CSS --><link rel=stylesheet href=https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css integrity=sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu crossorigin=anonymous><!-- Bootstrap Icons --><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css><link href=../../../assets/_mkdocstrings.css rel=stylesheet><link href=../../../assets/css/style.css rel=stylesheet></head> <body> <header> <div class="container-fluid top-bar"> <div class=brand> <a href=/ > <img src=../../../assets/img/fedbiomed-logo-small.png> </a> </div> <nav class=top> <ul> <li class> <a href=../../..>Home</a> </li> <li class> <a href=../../../getting-started/what-is-fedbiomed/ >User Documentation</a> </li> <li class> <a href=../../../pages/about-us/ >About</a> </li> <li id=clicker class=has-sub> More <i class="bi bi-chevron-down"></i> <ul class=sub-nav-menu> <li class> <a href=../../../#funding>Funding</a> </li> <li class> <a href=../../../news/ >News</a> </li> <li class> <a href=../../../#contributors>Contributors</a> </li> <li class> <a href=../../../#users>Users</a> </li> <li class> <a href=../../../pages/roadmap/ >Roadmap</a> </li> <li class> <a href=../../../#contact-us>Contact Us</a> </li> </ul> </li> </ul> </nav> </div> <div class="container-fluid top-bar-mobile"> <div class=mobile-bar> <div class=brand> <a href=../../../ > <img src=../../../assets/img/fedbiomed-logo-small.png> </a> </div> <div class=hum-menu> <img class=open src=../../../assets/img/menu.svg> <img class=close style=display:none src=../../../assets/img/cancel.svg> </div> </div> <nav class=top-mobile> <ul> <li class> <a href=../../..>Home</a> </li> <li class> <a href=../../../getting-started/what-is-fedbiomed/ >User Documentation</a> </li> <li class> <a href=../../../pages/about-us/ >About</a> </li> <li id=clicker class=has-sub> More <i class="bi bi-chevron-down"></i> <ul class=sub-nav-menu> <li class> <a href=../../../#funding>Funding</a> </li> <li class> <a href=../../../news/ >News</a> </li> <li class> <a href=../../../#contributors>Contributors</a> </li> <li class> <a href=../../../#users>Users</a> </li> <li class> <a href=../../../pages/roadmap/ >Roadmap</a> </li> <li class> <a href=../../../#contact-us>Contact Us</a> </li> </ul> </li> </ul> </nav> </div> </header> <div class=main> <!-- Home page --> <div class=container-fluid> <div class=doc-row> <div class=left-col> <div class=sidebar-doc> <nav class=sidebar-inner> <ul class="sidebar-menu-left sub"> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Getting Started <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../getting-started/what-is-fedbiomed/ class>What's Fed-BioMed</a> </li> <li class> <a href=../../../getting-started/getting-started/ class>Basic Example</a> </li> <li class> <a href=../../../getting-started/fedbiomed-architecture/ class>Fedbiomed Architecture</a> </li> <li class> <a href=../../../getting-started/fedbiomed-workflow/ class>Fedbiomed Workflow</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Tutorials <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Installation <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/installation/0-basic-software-installation/ class>Software Installation</a> </li> <li class> <a href=../../../tutorials/installation/1-setting-up-environment/ class>Setting Up Environment</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> PyTorch <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/pytorch/01_PyTorch_MNIST_Single_Node_Tutorial/ class>PyTorch MNIST Basic Example</a> </li> <li class> <a href=../../../tutorials/pytorch/02_Create_Your_Custom_Training_Plan/ class>How to Create Your Custom PyTorch Training Plan</a> </li> <li class> <a href=../../../tutorials/pytorch/03_PyTorch_Used_Cars_Dataset_Example/ class>PyTorch Used Cars Dataset Example</a> </li> <li class> <a href=../../../tutorials/pytorch/04-Aggregation_in_Fed-BioMed/ class>PyTorch aggregation methods in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> MONAI <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/monai/01_monai-2d-image-classification/ class>Federated 2d image classification with MONAI</a> </li> <li class> <a href=../../../tutorials/monai/02_monai-2d-image-registration/ class>Federated 2d XRay registration with MONAI</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Scikit-Learn <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/scikit-learn/01_sklearn_MNIST_classification_tutorial/ class>MNIST classification with Scikit-Learn Classifier (Perceptron)</a> </li> <li class> <a href=../../../tutorials/scikit-learn/02_sklearn_sgd_regressor_tutorial/ class>Fed-BioMed to train a federated SGD regressor model</a> </li> <li class> <a href=../../../tutorials/scikit-learn/03-other-scikit-learn-models/ class>Implementing other Scikit Learn models for Federated Learning</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Optimizers <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/optimizers/01-fedopt-and-scaffold/ class>Advanced optimizers in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> FLamby <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/flamby/flamby/ class>General Concepts</a> </li> <li class> <a href=../../../tutorials/flamby/flamby-integration-into-fedbiomed/ class>FLamby integration in Fed-BioMed</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Advanced <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/advanced/in-depth-experiment-configuration/ class>In Depth Experiment Configuration</a> </li> <li class> <a href=../../../tutorials/advanced/training-with-gpu/ class>PyTorch model training using a GPU</a> </li> <li class> <a href=../../../tutorials/advanced/breakpoints/ class>Breakpoints</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Security <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/security/differential-privacy-with-opacus-on-fedbiomed/ class>Using Differential Privacy with OPACUS on Fed-BioMed</a> </li> <li class> <a href=../../../tutorials/security/non-private-local-central-dp-monai-2d-image-registration/ class>Local and Central DP with Fed-BioMed: MONAI 2d image registration</a> </li> <li class> <a href=../../../tutorials/security/training-with-approved-training-plans/ class>Training Process with Training Plan Management</a> </li> <li class> <a href=../../../tutorials/security/secure-aggregation/ class>Training with Secure Aggregation</a> </li> <li class> <a href=../../../tutorials/concrete-ml/concrete-ml/ class>End-to-end Privacy Preserving Training and Inference on Medical Data</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Biomedical data <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../tutorials/medical/medical-image-segmentation-unet-library/ class>Brain Segmentation</a> </li> </ul> </li> </ul> </li> <li data-adress=sub-1 class="current has-sub-side"> <div href class="parent-list current "> User Guide <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub active "> <li class> <a href=../../glossary/ class>Glossary</a> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Deployment <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../deployment/deployment/ class>Introduction</a> </li> <li class> <a href=../../deployment/deployment-vpn/ class>VPN Deployment</a> </li> <li class> <a href=../../deployment/matrix/ class>Network matrix</a> </li> <li class> <a href=../../deployment/security-model/ class>Security model</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Node <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../nodes/configuring-nodes/ class>Configuring Nodes</a> </li> <li class> <a href=../../nodes/deploying-datasets/ class>Deploying Datasets</a> </li> <li class> <a href=../../nodes/training-plan-security-manager/ class>Training Plan Management</a> </li> <li class> <a href=../../nodes/using-gpu/ class>Using GPU</a> </li> <li class> <a href=../../nodes/node-gui/ class>Node GUI</a> </li> </ul> </li> <li data-adress=sub-1 class="current has-sub-side"> <div href class="parent-list current "> Researcher <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub active "> <li class=current> <a href=./ class="link current">Training Plan</a> </li> <li class> <a href=../training-data/ class>Training Data</a> </li> <li class> <a href=../experiment/ class>Experiment</a> </li> <li class> <a href=../aggregation/ class>Aggregation</a> </li> <li class> <a href=../listing-datasets-and-selecting-nodes/ class>Listing Datasets and Selecting Nodes</a> </li> <li class> <a href=../model-testing-during-federated-training/ class>Model Validation on the Node Side</a> </li> <li class> <a href=../tensorboard/ class>Tensorboard</a> </li> </ul> </li> <li class> <a href=../../advanced-optimization/ class>Optimization</a> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Secure Aggregation <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../secagg/introduction/ class>Introduction</a> </li> <li class> <a href=../../secagg/configuration/ class>Configuration</a> </li> <li class> <a href=../../secagg/certificate-registration/ class>Certificate Registration</a> </li> <li class> <a href=../../secagg/researcher-interface/ class>Managing Secure Aggregation in Researcher</a> </li> </ul> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Developer <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> API Reference <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Common <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../developer/api/common/constants/ class>Constants</a> </li> <li class> <a href=../../../developer/api/common/data/ class>Data</a> </li> <li class> <a href=../../../developer/api/common/environ/ class>Environ</a> </li> <li class> <a href=../../../developer/api/common/exceptions/ class>Exceptions</a> </li> <li class> <a class href=../../../developer/api/common/json.md>Json</a> </li> <li class> <a href=../../../developer/api/common/logger/ class>Logger</a> </li> <li class> <a href=../../../developer/api/common/message/ class>Message</a> </li> <li class> <a class href=../../../developer/api/common/messaging.md>Messaging</a> </li> <li class> <a href=../../../developer/api/common/models/ class>Model</a> </li> <li class> <a href=../../../developer/api/common/optimizers/ class>Optimizers</a> </li> <li class> <a class href=../../../developer/api/common/repository.md>Repository</a> </li> <li class> <a href=../../../developer/api/common/tasks_queue/ class>TasksQueue</a> </li> <li class> <a href=../../../developer/api/common/training_plans/ class>TrainingPlans</a> </li> <li class> <a href=../../../developer/api/common/training_args/ class>TrainingArgs</a> </li> <li class> <a href=../../../developer/api/common/utils/ class>Utils</a> </li> <li class> <a href=../../../developer/api/common/validator/ class>Validator</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Node <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../developer/api/node/cli/ class>CLI</a> </li> <li class> <a href=../../../developer/api/node/dataset_manager/ class>DatasetManager</a> </li> <li class> <a href=../../../developer/api/node/node/ class>Node</a> </li> <li class> <a href=../../../developer/api/node/node_state_manager/ class>NodeStateManager</a> </li> <li class> <a href=../../../developer/api/node/training_plan_security_manager/ class>TrainingPlanSecurityManager</a> </li> <li class> <a href=../../../developer/api/node/history_monitor/ class>HistoryMonitor</a> </li> <li class> <a href=../../../developer/api/node/round/ class>Round</a> </li> </ul> </li> <li data-adress=sub-1 class=has-sub-side> <div href class="parent-list "> Researcher <i class="bi bi-chevron-down"></i> </div> <ul class="sub-sidebar-menu sub "> <li class> <a href=../../../developer/api/researcher/aggregators/ class>Aggregators</a> </li> <li class> <a href=../../../developer/api/researcher/datasets/ class>Datasets</a> </li> <li class> <a href=../../../developer/api/researcher/experiment/ class>Experiment</a> </li> <li class> <a href=../../../developer/api/researcher/filetools/ class>Filetools</a> </li> <li class> <a href=../../../developer/api/researcher/jobs/ class>Jobs</a> </li> <li class> <a href=../../../developer/api/researcher/monitor/ class>Monitor</a> </li> <li class> <a href=../../../developer/api/researcher/node_state_agent/ class>NodeStateAgent</a> </li> <li class> <a href=../../../developer/api/researcher/requests/ class>Requests</a> </li> <li class> <a href=../../../developer/api/researcher/strategies/ class>Strategies</a> </li> <li class> <a href=../../../developer/api/researcher/secagg/ class>Secagg</a> </li> </ul> </li> </ul> </li> <li class> <a href=../../../developer/usage_and_tools/ class>Usage and Tools</a> </li> <li class> <a href=../../../developer/ci/ class>Continuous Integration</a> </li> <li class> <a href=../../../developer/definition-of-done/ class>Definition of Done</a> </li> <li class> <a href=../../../developer/testing-in-fedbiomed/ class>Testing in Fed-BioMed</a> </li> <li class> <a href=../../../developer/messaging/ class>RPC Protocol and Messages</a> </li> </ul> </li> </ul> </nav> </div> </div> <div class=main-col> <main class=main-docs> <article> <h1 id=the-training-plan>The Training Plan</h1> <p>A training plan is a class that defines the four main components of federated model training: the data, the model, the loss and the optimizer. It is responsible for providing custom methods allowing every node to perform the training. In Fed-BioMed, you will be required to define a training plan class before submitting a federated training experiment. You will do so by sub-classing one of the base training plan classes provided by the library, and overriding certain methods to suit your needs as explained below. The code of the whole training plan class is shipped to the nodes, meaning that you may define custom classes and functions inside it, and re-use them within the training routine. </p> <div class="admonition abstract"> <p class=admonition-title>Training Plans</p> <p>A Training Plan contains the recipe for executing the training loop on the nodes. It defines: the data, the model, the loss function, and the optimizer. The code in the training plan is shipped in its entirety to the nodes, where its different parts are executed at different times during the training loop.</p> </div> <h2 id=the-trainingplan-class>The <code>TrainingPlan</code> class</h2> <p>Fed-BioMed provides a base training plan class for two commonly-used ML frameworks: PyTorch (<code>fedbiomed.common.training_plans.TorchTrainingPlan</code>) and scikit-learn (<code>fedbiomed.common.training_plans.SKLearnTrainingPlan</code>). Therefore, the first step of the definition of your federated training experiment will be to define a new training plan class that inherits from one of these. </p> <h3 id=pytorch-training-plan>Pytorch Training Plan</h3> <p>The interfaces for the two frameworks differ quite a bit, so let's start by taking the example of PyTorch:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>TorchTrainingPlan</span>


<span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>TorchTrainingPlan</span><span class=p>):</span>
    <span class=k>pass</span>
</code></pre></div> <p>The above example will not lead to a meaningful experiment, because we need to provide at least the following information to complete our training plan:</p> <ul> <li>a model instance</li> <li>an optimizer instance</li> <li>a list of dependencies (i.e. modules to be imported before instantiating the model and optimizer)</li> <li>how to load the training data (and potential preprocessing)</li> <li>a loss function</li> </ul> <p>Following the PyTorch example, here is what the prototype of your training plan would look like: <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>TorchTrainingPlan</span>

<span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>TorchTrainingPlan</span><span class=p>):</span>
    <span class=k>def</span> <span class=nf>init_model</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_args</span><span class=p>):</span>
        <span class=c1># defines and returns a model</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>init_optimizer</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>optimizer_args</span><span class=p>):</span>
        <span class=c1># defines and returns an optimizer</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># returns a list of dependencies</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># returns a Fed-BioMed DataManager object</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>):</span>
        <span class=c1># returns the loss</span>
        <span class=k>pass</span>
</code></pre></div></p> <h3 id=scikit-learn-training-plan>Scikit-learn Training Plan</h3> <p>In the case of scikit-learn, Fed-BioMed already does a lot of the heavy lifting for you by providing the <code>FedPerceptron</code>, <code>FedSGDClassifier</code> and <code>FedSGDRegressor</code> classes as training plans. These classes already take care of the model and loss functions for you, so you only need to define how the data will be loaded, how to optimize the model and the dependencies. For example, in the case of <code>FedSGDClassifier</code>:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>FedSGDClassifier</span>

<span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>FedSGDClassifier</span><span class=p>):</span>
    <span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># returns a Fed-BioMed DataManager object</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>init_optimizer</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>optimizer_args</span><span class=p>):</span>
        <span class=c1># defines and returns an optimizer: only declearn optimizer are permitted here</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># returns a list of dependencies</span>
        <span class=k>pass</span>
</code></pre></div> <h3 id=_1></h3> <div class="admonition warning"> <p class=admonition-title>Definition of <code>__init__</code> is discouraged for all training plans</p> <p>As you may have noticed, none of the examples defined an <code>__init__</code> function for the training plan. This is on purpose! Overriding <code>__init__</code> is not required, and is actually discouraged, as it is reserved for the library's internal use. If you decide to override it, you do it at your own risk!</p> </div> <h2 id=accessing-the-training-plan-attributes>Accessing the Training Plan attributes</h2> <p>Fed-BioMed provides the following getter functions to access Training Plan attributes:</p> <table> <thead> <tr> <th>attribute</th> <th>function</th> <th>TorchTrainingPlan</th> <th>SKLearnTrainingPlan</th> <th>notes</th> </tr> </thead> <tbody> <tr> <td>model</td> <td><code>model()</code></td> <td><img alt=✔ class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/2714.svg title=:heavy_check_mark:></td> <td><img alt=✔ class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/2714.svg title=:heavy_check_mark:></td> <td>you may not dynamically reassign a model. The instance of the model is created at initialization by storing the output of the <code>init_model</code> function.</td> </tr> <tr> <td>optimizer</td> <td><code>optimizer()</code></td> <td><img alt=✔ class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/2714.svg title=:heavy_check_mark:></td> <td><img alt=✔ class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/2714.svg title=:heavy_check_mark:></td> <td>you may not dynamically reassign an optimizer. The instance of the optimizer is created at initialization by storing the output of the <code>init_optimizer</code> function.</td> </tr> <tr> <td>model arguments</td> <td><code>model_args()</code></td> <td><img alt=✔ class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/2714.svg title=:heavy_check_mark:></td> <td><img alt=✔ class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/2714.svg title=:heavy_check_mark:></td> <td></td> </tr> <tr> <td>training arguments</td> <td><code>training_args()</code></td> <td><img alt=✔ class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/2714.svg title=:heavy_check_mark:></td> <td><img alt=✔ class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/2714.svg title=:heavy_check_mark:></td> <td></td> </tr> <tr> <td>optimizer arguments</td> <td><code>optimizer_args()</code></td> <td><img alt=✔ class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/2714.svg title=:heavy_check_mark:></td> <td><img alt=✔ class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/2714.svg title=:heavy_check_mark:></td> <td></td> </tr> </tbody> </table> <h4 id=_2></h4> <div class="admonition warning"> <p class=admonition-title>Lifecycle of Training Plan Attributes</p> <p>The attributes in the table above will not be available during the <code>init_model</code>, <code>init_optimizer</code> and <code>init_dependencies</code> functions, as they are set just after initialization. You may however use them in the definition of <code>training_data</code>, <code>training_step</code> or <code>training_routine</code>.</p> </div> <h2 id=defining-the-training-data>Defining the training data</h2> <p>The method <code>training_data</code> defines how datasets should be loaded in nodes to make them ready for training. In both PyTorch and scikit-learn training plans, you are required to define a <code>training_data</code> method with the following specs:</p> <ol> <li>takes as input a <code>batch_size</code> parameter</li> <li>returns a <code>fedbiomed.common.data.DataManager</code> object</li> <li>inside the method, a dataset is instantiated according to the data type that you wish to use (one of <code>torch.Dataset</code>, <code>numpy.ndarray</code> or a <code>*Dataset</code> class from the <code>fedbiomed.common.data</code> module)</li> <li>the dataset is used to initialize a <code>DataManager</code> class to be returned</li> </ol> <p>The signature of the <code>training_data</code> function is then: <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataManager</span><span class=p>:</span>
</code></pre></div></p> <p>You can read the documentation for <a href=../../researcher/training-data>training data</a> to learn more about the <code>DataManager</code> class and various use cases.</p> <h2 id=initializing-the-model>Initializing the model</h2> <p>In Pytorch training plans, you must also define a <code>init_model</code> function with the following signature: <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>init_model</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_args</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>:</span>
</code></pre></div></p> <p>The purpose of <code>init_model</code> is to return an instance of a trainable PyTorch model. Since the definition of such models can be quite large, a common pattern is to define the neural network class inside the training plan namespace, and simply instantiate it within <code>init_model</code>. This also allows to minimize the amount of adjustments needed to go from local PyTorch code to its federated version. Remember that only the code defined inside the training plan namespace will be shipped to the nodes for execution, so you may not use classes that are defined outside of it.</p> <p>The Pytorch neural network class that you define must satisfy the following constraints: 1. it should inherit from <code>torch.nn.Module</code> 2. it should implement a <code>forward</code> method that takes a <code>torch.Tensor</code> as input and returns a <code>torch.Tensor</code> Note that inheriting from <code>torch.nn.Sequential</code> and using the default <code>forward</code> method would also respect the conditions above. </p> <p>The <code>model_args</code> argument is a dictionary of model arguments that you may provide to the <code>Experiment</code> class and that will be automatically passed to the <code>init_model</code> function internally. If you followed the suggested pattern of defining the model class within the training plan namespace, you can easily adapt the model's constructor to make use of any model arguments that you wish to define.</p> <p>The example below, adapted from our getting started notebook, shows the suggested pattern, the use of <code>init_model</code>, and the use of <code>model_args</code>.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.training_plans</span> <span class=kn>import</span> <span class=n>TorchTrainingPlan</span>
<span class=kn>from</span> <span class=nn>fedbiomed.common.data</span> <span class=kn>import</span> <span class=n>DataManager</span>


<span class=c1># Here we define the model to be used. </span>
<span class=c1># You can use any class name (here &#39;Net&#39;)</span>
<span class=k>class</span> <span class=nc>MyTrainingPlan</span><span class=p>(</span><span class=n>TorchTrainingPlan</span><span class=p>):</span>

    <span class=c1># Defines and return model </span>
    <span class=k>def</span> <span class=nf>init_model</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_args</span><span class=p>):</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>Net</span><span class=p>(</span><span class=n>model_args</span> <span class=o>=</span> <span class=n>model_args</span><span class=p>)</span>

    <span class=k>class</span> <span class=nc>Net</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
        <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_args</span><span class=p>):</span>
            <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

            <span class=n>fc_hidden_layer_size</span> <span class=o>=</span> <span class=n>model_args</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;fc_hidden_size&#39;</span><span class=p>,</span> <span class=mi>128</span><span class=p>)</span>

            <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>dropout1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.25</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>dropout2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>9216</span><span class=p>,</span> <span class=n>fc_hidden_layer_size</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>fc_hidden_layer_size</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>

        <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
            <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
            <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
            <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>max_pool2d</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
            <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
            <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

            <span class=n>output</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>log_softmax</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
            <span class=k>return</span> <span class=n>output</span>

    <span class=k>def</span> <span class=nf>training_data</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>pass</span>    

    <span class=k>def</span> <span class=nf>training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>):</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>init_optimizer</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>optimizer_args</span><span class=p>):</span>
        <span class=k>pass</span>

    <span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>pass</span>
</code></pre></div> <h2 id=defining-the-optimizer>Defining the optimizer</h2> <h3 id=optimizer-in-pytorch-training-plans>Optimizer in PyTorch Training Plans</h3> <p>In Pytorch training plans, you must also define a <code>init_optimizer</code> function with the following signature:</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>init_optimizer</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>optimizer_args</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>Union</span><span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Optimizer</span><span class=p>,</span> <span class=n>fedbiomed</span><span class=o>.</span><span class=n>common</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>Optimizer</span><span class=p>]:</span>
</code></pre></div> <p>The purpose of <code>init_optimizer</code> is to return an instance of a PyTorch optimizer or a <code>Fed-BioMed</code> optimizer powered with <code>declearn</code> optimizzation modules. You may instantiate a "vanilla" optimizer directly from <code>torch.optim</code>, or follow a similar pattern to <code>init_model</code> by defining a custom optimizer class within the training plan namespace. </p> <h4 id=_3></h4> <div class="admonition info"> <p class=admonition-title>The output of <code>init_optimizer</code> must be either a <code>torch.optim</code> type or a <code>fedbiomed.common.optimizer.Optimizer</code></p> <p>The output of <code>init_optimizer</code> must be either a vanilla optimizer provided by the <code>torch.optim</code> module, or a class that inherits from <code>torch.optim.Optimizer</code>, or a <a href=../../../developer/api/common/optimizer><code>fedbiomed.common.optimizer.Optimizer</code></a>, populated with <code>declearn</code>'s <code>OptiModules</code> and <code>Regularizers</code>.</p> </div> <div class="admonition note"> <p class=admonition-title>About declearn</p> <p><code>declearn</code> provides a cross framework optimizers that can be used regardless of the machine learning framework. It also provides well known federated learning algorithms such as <code>Scaffold</code>. For further details on <code>declearn</code>'s <code>Optimizer</code>, <a href=./../../advanced-optimization>please visit the following webpage</a>.</p> </div> <p>Similarly, the <code>optimizer_args</code> follow the same pattern as <code>model_args</code> described above. Note that the learning rate will always be included in the optimizer arguments with the key <code>lr</code>.</p> <p>A pretty straightforward example can be again found in the getting started notebook</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>init_optimizer</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>optimizer_args</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>()</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span> <span class=o>=</span> <span class=n>optimizer_args</span><span class=p>[</span><span class=s2>&quot;lr&quot;</span><span class=p>])</span>
</code></pre></div> <h3 id=optimizer-in-scikit-learn-training-plans>Optimizer in scikit-learn Training Plans</h3> <p>In Scikit-Learn <code>Training Plans</code>, only <code>fedbimed.common.optimizer.Optimizer</code> optimizers can be defined in the <code>init_optimizer</code> method. Hence, its signature is:</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>init_optimizer</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>optimizer_args</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>fedbiomed</span><span class=o>.</span><span class=n>common</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>Optimizer</span><span class=p>:</span>
</code></pre></div> <h2 id=defining-the-loss-function>Defining the loss function</h2> <p>The PyTorch training plan requires you to define the loss function via the <code>training_step</code> method, with the following signature:</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
</code></pre></div> <p>The <code>training_step</code> method of the training class defines how the cost is computed by forwarding input values through the network and using the loss function. It should return the loss value. By default, it is not defined in the parent <code>TrainingPlan</code> class: it should be defined by the researcher in his/her model class, same as the <code>forward</code> method.<br> An example of training step for PyTorch is shown below.</p> <div class=highlight><pre><span></span><code>    <span class=k>def</span> <span class=nf>training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>):</span>
        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>forward</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
        <span class=n>loss</span>   <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>nll_loss</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>loss</span>
</code></pre></div> <h3 id=type-of-data-and-target>Type of <code>data</code> and <code>target</code></h3> <p>The <code>training_step</code> function takes as input two arguments, <code>data</code> and <code>target</code>, which are obtained by cycling through the dataset defined in the <code>training_data</code> function. There is some flexibility concerning what type of variables they might be. </p> <p>In a Pytorch training plan, the following data types are supported: </p> <ul> <li>a <code>torch.Tensor</code></li> <li>a collection (a <code>dict</code>, <code>tuple</code> or <code>list</code>) of <code>torch.Tensor</code></li> <li>a recursive collection of collections, arbitrarily nested, that ultimately contain <code>torch.Tensor</code> objects</li> </ul> <div class="admonition warning"> <p class=admonition-title>Be aware of the data types in your dataset</p> <p>It is ultimately your responsibility to write the code for <code>training_step</code> that correctly handles the data types returned by the <code>__getitem__</code> function of the dataset you are targeting. Be aware of the specifics of your dataset when writing this function.</p> </div> <h2 id=adding-dependencies>Adding Dependencies</h2> <p>By dependencies we mean here the python modules that are necessary to build all the various elements of your training plan on the node side.<br> The method <code>init_dependencies</code> allows you to indicate modules that are needed by your model class, with the following signature:</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>init_dependencies</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
</code></pre></div> <p>Each dependency should be defined as valid import statement in a string, for example <code>from torch.optim import Adam</code> or <code>import torch</code>, or <code>from declearn.optimizer.modules import AdamModule</code> (for its <code>declearn</code> alternative). You must specify dependencies for any python module that you wish to use, regardless of whether it is for the data, optimizer, model, etc...</p> <h2 id=training_routine><code>training_routine</code></h2> <p>The training routine is the heart of the training plan. This method performs the model training loop, based on given <a href=../../researcher/experiment>model and training</a> arguments. For example, if the model is a neural network based on the PyTorch framework, the training routine is in charge of performing the training part over looping epochs and batches. If the model is a Scikit-Learn model, it fits the model by the given ML method and Scikit-Learn does the rest. The training routine is executed by the nodes after they have received a train request from the researcher and downloaded the training plan file.</p> <div class="admonition warning"> <p class=admonition-title>Overriding <code>training_routine</code> is discouraged</p> <p>Both PyTorch and scikit-learn training plans already implement a <code>training_routine</code>, that internally uses the <code>training_step</code> provided by you to compute the loss function (only in the PyTorch case). Overriding this default routine is strongly discouraged, and you may do so only at your own risk.</p> </div> <p>As you can see from the following code snippet, the training routine requires some training arguments such as <code>epochs</code>, <code>lr</code>, <code>batch_size</code> etc. Since the <code>training_routine</code> is already defined by Fed-BioMed, you are only allowed to control the training process by changing these arguments. Modifying the training routine from the training plan class might raise unexpected errors.</p> <div class=highlight><pre><span></span><code> <span class=k>def</span> <span class=nf>training_routine</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span>
                         <span class=n>epochs</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>2</span><span class=p>,</span>
                         <span class=n>log_interval</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>10</span><span class=p>,</span>
                         <span class=n>lr</span><span class=p>:</span> <span class=n>Union</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=nb>float</span><span class=p>]</span> <span class=o>=</span> <span class=mf>1e-3</span><span class=p>,</span>
                         <span class=n>batch_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>48</span><span class=p>,</span>
                         <span class=n>batch_maxnum</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span>
                         <span class=n>dry_run</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
                         <span class=o>...</span> <span class=p>):</span>

        <span class=c1># You can see details from `fedbiomed.common.torchnn`</span>
        <span class=c1># .....</span>

        <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>epochs</span> <span class=o>+</span> <span class=mi>1</span><span class=p>):</span>
            <span class=n>training_data</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>training_data</span><span class=p>()</span>
            <span class=k>for</span> <span class=n>batch_idx</span><span class=p>,</span> <span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>training_data</span><span class=p>):</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>train</span><span class=p>()</span> 
                <span class=n>data</span><span class=p>,</span> <span class=n>target</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>),</span> <span class=n>target</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
                <span class=n>res</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>training_step</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
                <span class=n>res</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

                <span class=c1>#.....</span>
</code></pre></div> <h2 id=exporting-and-importing-model>Exporting and importing model</h2> <p>Each training plan provides export and import functionality.</p> <ul> <li>Export facility is used for saving model parameters to a file after training the model in Fed-BioMed, so it can be used in another software (eg for inference).</li> <li>Import facility is used for loading model parameters from a file, for example to specialize with Fed-BioMed a model pre-trained with another software (transfer learning) or a previous Fed-BioMed run.</li> </ul> <p><strong>Exports</strong> and <strong>imports</strong> are handled through the <a href=../../researcher/experiment><code>Experiment</code></a> interface. <a href=../../researcher/experiment><code>Experiment</code></a> interface will initialize the model for you, by calling internally <code>Training Plan</code> methods <code>init_method</code> and <code>post_init</code>. See example below for an instantiated <code>Experiment</code> object named <code>exp</code>.</p> <p>To save model to file <code>/path/to/file</code> use:</p> <div class=highlight><pre><span></span><code><span class=n>exp</span><span class=o>.</span><span class=n>training_plan</span><span class=p>()</span><span class=o>.</span><span class=n>export_model</span><span class=p>(</span><span class=s1>&#39;/path/to_file&#39;</span><span class=p>)</span>
</code></pre></div> <p>To load model from file <code>/path/to/file</code> use:</p> <div class=highlight><pre><span></span><code><span class=n>exp</span><span class=o>.</span><span class=n>training_plan</span><span class=p>()</span><span class=o>.</span><span class=n>import_model</span><span class=p>(</span><span class=s1>&#39;/path/to_file&#39;</span><span class=p>)</span>
</code></pre></div> <p>Of course, loaded model needs to be identical to the training plan's model.</p> <div class="admonition info"> <p class=admonition-title><code>export_model()</code> and <code>import_model()</code> actions depends on framework</p> <p>With PyTorch, these methods save and load the model parameters (<code>model.state_dict()</code>) with <code>torch.save()</code>/<code>torch.load()</code> as it is a <a href=https://pytorch.org/tutorials/beginner/saving_loading_models.html>common practice</a></p> <p>With scikit-learn, these methods save and load the whole model with <code>joblib.dump()</code>/<code>joblib.load()</code> as it is also a <a href=https://scikit-learn.org/stable/model_persistence.html>common practice</a></p> </div> <div class="admonition warning"> <p class=admonition-title>Security notice</p> <p>Only use <code>import_model()</code> with a trusted model file (trained by a trusted source, transmitted via secure channel).</p> <p>In both PyTorch and scikit-learn, the model saving and loading facility are based on <a href=https://docs.python.org/3/library/pickle.html>pickle</a>. While it is the recommended way of saving models in these frameworks, a malicious pickle model can execute arbitrary code on your machine when loaded. Thus make sure you are loading a model from a reliable source.</p> </div> <div class="admonition warning"> <p class=admonition-title>Usage through <code>Experiment</code></p> <p>Both <strong>exports</strong> and <strong>imports</strong> must be used through <a href=../../researcher/experiment>Experiment</a> interface. Indeed, <code>Experiment</code> class has methods to load Training Plans and for initializing Model. Once the Model is initialized, you can use both <code>export_model</code> and <code>import_model</code> for saving model into a file and respectively load it from a file.</p> </div> </article> </main> </div> <div class=right-col> <div id=right-sidebar class=sidebar-right> <nav class=toc> <!-- Render item list --> <label class=toc-title for=__toc> <span class=toc-icon></span> </label> <ul class=toc-list data-md-component=toc data-md-scrollfix> <!-- Table of contents item --> <li class=toc-item> <a href=#the-trainingplan-class class=md-nav__link> The TrainingPlan class </a> <nav class=toc-nav aria-label="The TrainingPlan class"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#pytorch-training-plan class=md-nav__link> Pytorch Training Plan </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#scikit-learn-training-plan class=md-nav__link> Scikit-learn Training Plan </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#_1 class=md-nav__link> </a> </li> </ul> </nav> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#accessing-the-training-plan-attributes class=md-nav__link> Accessing the Training Plan attributes </a> <nav class=toc-nav aria-label="Accessing the Training Plan attributes"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#_2 class=md-nav__link> </a> </li> </ul> </nav> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#defining-the-training-data class=md-nav__link> Defining the training data </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#initializing-the-model class=md-nav__link> Initializing the model </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#defining-the-optimizer class=md-nav__link> Defining the optimizer </a> <nav class=toc-nav aria-label="Defining the optimizer"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#optimizer-in-pytorch-training-plans class=md-nav__link> Optimizer in PyTorch Training Plans </a> <nav class=toc-nav aria-label="Optimizer in PyTorch Training Plans"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#_3 class=md-nav__link> </a> </li> </ul> </nav> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#optimizer-in-scikit-learn-training-plans class=md-nav__link> Optimizer in scikit-learn Training Plans </a> </li> </ul> </nav> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#defining-the-loss-function class=md-nav__link> Defining the loss function </a> <nav class=toc-nav aria-label="Defining the loss function"> <ul class=toc-list> <!-- Table of contents item --> <li class=toc-item> <a href=#type-of-data-and-target class=md-nav__link> Type of data and target </a> </li> </ul> </nav> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#adding-dependencies class=md-nav__link> Adding Dependencies </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#training_routine class=md-nav__link> training_routine </a> </li> <!-- Table of contents item --> <li class=toc-item> <a href=#exporting-and-importing-model class=md-nav__link> Exporting and importing model </a> </li> </ul> </nav> </div> </div> </div> </div> <!-- News Main Page--> </div> <footer> <div class=container-fluid> <div class=footer-first-inner> <div class=container> <div class=row> <div class=col-md-6> <div class=footer-contact> <strong>Address:</strong> <p>2004 Rte des Lucioles, 06902 Sophia Antipolis</p> <strong>E-mail:</strong> <p>fedbiomed _at_ inria _dot_ fr</p> </div> </div> <div class=col-md-6> <div class=footer-contact> <p>Fed-BioMed © 2022</p> </div> </div> </div> </div> </div> </div> </footer> <!-- JQuery --> <script src=https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js></script> <!-- Latest compiled and minified JavaScript --> <script src=https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js integrity=sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd crossorigin=anonymous></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/tablesort/5.2.1/tablesort.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../../assets/javascript/lunr.js></script> <script src=../../../assets/javascript/theme.js></script> </body> </html>